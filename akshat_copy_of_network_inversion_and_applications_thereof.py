# -*- coding: utf-8 -*-
"""Akshat_Copy_of_Network_Inversion_and_Applications_Thereof.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZUxoQPiMOcm81HGcvGgal9keIqzGAVB2
"""

import os
import cv2
import glob
import torch
import numpy as np
from PIL import Image
import torch.nn as nn
from tqdm import tqdm
import torch.optim as optim
import torchvision.utils as vutils
import torch.nn.functional as F
import matplotlib.pyplot as plt
from torchvision import transforms
from torch.utils.data import Dataset
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms.functional as TF
from sklearn.preprocessing import MinMaxScaler
from torchvision.datasets import ImageFolder
from torchvision import datasets, transforms

import os
import shutil
from torchvision import datasets

# Define paths
mnist_root = './data/MNIST'
train_data_dir = os.path.join(mnist_root, 'train')
test_data_dir = os.path.join(mnist_root, 'test')

# Make sure the directories exist
os.makedirs(train_data_dir, exist_ok=True)
os.makedirs(test_data_dir, exist_ok=True)

# Download the MNIST dataset
train_set = datasets.MNIST(root=mnist_root, train=True, download=True)
test_set = datasets.MNIST(root=mnist_root, train=False, download=True)

# Move images into class-specific folders
for idx, (image, label) in enumerate(train_set):
    label_dir = os.path.join(train_data_dir, str(label))
    os.makedirs(label_dir, exist_ok=True)
    image.save(os.path.join(label_dir, f"{idx}.png"))

for idx, (image, label) in enumerate(test_set):
    label_dir = os.path.join(test_data_dir, str(label))
    os.makedirs(label_dir, exist_ok=True)
    image.save(os.path.join(label_dir, f"{idx}.png"))

# Define the path to your MNIST dataset
train_data_dir = 'data/MNIST/train'
test_data_dir = 'data/MNIST/test'

# Set device (CPU or GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define data transformations with MNIST mean and standard deviation
mnist_mean = 0.1307
mnist_std = 0.3081
batch_size= 8192
# Define data transformations for training and testing
train_transform = transforms.Compose([
    transforms.RandomRotation(degrees=(-20, 20)),
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.9, 1.1)),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
    transforms.RandomGrayscale(p=0.1),
    transforms.RandomAffine(degrees=(-10, 10), translate=(0.1, 0.1), scale=(0.9, 1.1), shear=(-10, 10)),
    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize(28),
    transforms.ToTensor(),
    transforms.Normalize((mnist_mean,), (mnist_std,))
])

test_transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize(28),
    transforms.ToTensor(),
    transforms.Normalize((mnist_mean,), (mnist_std,))
])

# Load the MNIST dataset using ImageFolder
# train_dataset = ImageFolder(root=train_data_dir, transform=train_transform)
# test_dataset = ImageFolder(root=test_data_dir, transform=test_transform)
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=train_transform)
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=test_transform)


# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory = True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory = True)

print("Training Dataset:")
print(f"  Size: {len(train_dataset)}")
print(f"  Shape: {next(iter(train_loader))[0].shape}")
print(f"  Batch Size: {train_loader.batch_size}")

print("\nTesting Dataset:")
print(f"  Size: {len(test_dataset)}")
print(f"  Shape: {next(iter(test_loader))[0].shape}")
print(f"  Batch Size: {test_loader.batch_size}")

# Dictionary to store images for each class
class_images = {i: [] for i in range(10)}

# Traverse through the folder and collect images
for class_label in range(10):
    class_path = os.path.join(train_data_dir, str(class_label))

    # Iterate through images in the class folder
    for image_file in os.listdir(class_path)[:10]:
        image_path = os.path.join(class_path, image_file)
        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        class_images[class_label].append(image)

# Plot 10x10 grid
fig, axs = plt.subplots(10, 10, figsize=(10, 10))

for i in range(10):
    for j in range(10):
        axs[i, j].imshow(class_images[i][j], cmap="gray")
        axs[i, j].axis("off")

plt.show()

"""Classifier"""

class Classifier(nn.Module):
    def __init__(self, nc, ncf):
        super(Classifier, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(nc, ncf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ncf),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ncf, ncf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ncf * 2),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ncf * 2, ncf * 4, 3, 1, 0, bias=False),
            nn.Flatten(),
            nn.Linear(ncf * 100, ncf * 2),
            nn.ReLU(),

            nn.Linear(ncf * 2, 10)
        )

    def forward(self, input):
        return self.main(input)

class Generator(nn.Module):
    def __init__(self, nz, ngf, nc, n_classes):
        super(Generator, self).__init__()
        # Linear layer to map the softmaxed vector to the size nz
        self.embed = nn.Linear(n_classes, nz)

        # The main model architecture remains unchanged
        self.main = nn.Sequential(
            nn.ConvTranspose2d(nz * 2, ngf * 4, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.Dropout2d(0.2),
            nn.Dropout2d(0.3),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.Dropout2d(0.2),
            nn.Dropout2d(0.3),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 2, bias=False),
            nn.BatchNorm2d(ngf),
            nn.Dropout2d(0.2),
            nn.Dropout2d(0.3),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, z, class_vector):
        # Map the class vector to the latent space size
        embed_vector = self.embed(class_vector).unsqueeze(-1).unsqueeze(-1)
        # Concatenate with the latent vector z
        input = torch.cat([z, embed_vector], 1)
        return self.main(input)

def weights_initialization_cnn(m):
    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)

def train(model, train_loader, optimizer, criterion, device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc="Training")

    for i, (inputs, labels) in pbar:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        pbar.set_postfix({"Batch Loss": loss.item()})

    average_loss = running_loss / len(train_loader)
    accuracy = correct / total

    return average_loss, accuracy

def test(model, test_loader, device):
    model.eval()
    correct = 0
    total = 0
    running_loss = 0.0

    with torch.no_grad():
        pbar = tqdm(enumerate(test_loader), total=len(test_loader), desc="Testing")

        for i, (inputs, labels) in pbar:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            running_loss += loss.item()

            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            pbar.set_postfix({"Batch Loss": loss.item()})

    average_loss = running_loss / len(test_loader)
    accuracy = correct / total

    return average_loss, accuracy

# Classifier Hyperparameters
ncf = 64  # Number of classifier filters
nc = 1    # Number of channels in the input images (1 for grayscale)

# Initialize your model, optimizer, and criterion
csf = Classifier(nc, ncf).to(device)
csf.apply(weights_initialization_cnn)

csf_optimizer = optim.Adam(csf.parameters(), lr=0.01)
criterion = nn.CrossEntropyLoss()

# Lists to store the training and testing loss and accuracy values
train_losses = []
train_accuracies = []
test_losses = []
test_accuracies = []

# Variable to store the best test accuracy
best_test_accuracy = 0.0
best_model_state = None

# Training loop for 10 epochs
num_epochs = 25
for epoch in range(num_epochs):
    # Training
    train_loss, train_accuracy = train(csf, train_loader, csf_optimizer, criterion, device)
    train_losses.append(train_loss)
    train_accuracies.append(train_accuracy)

    # Testing
    test_loss, test_accuracy = test(csf, test_loader, device)
    test_losses.append(test_loss)
    test_accuracies.append(test_accuracy)

    # Check if this is the best model so far
    if test_accuracy > best_test_accuracy:
        best_test_accuracy = test_accuracy
        best_model_state = csf.state_dict()

    print(f"\nEpoch {epoch + 1}/{num_epochs}")
    print(f"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}")
    print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")

# Save the best model
if best_model_state is not None:
    torch.save(best_model_state, 'MNIST-Inversion/mnist_csf_10.pth')
    print(f"Best model saved with test accuracy: {best_test_accuracy:.4f}")
else:
    print("No model was saved.")



csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

features0=[]
def hook_function0(module, input, output):
    # This function saves the output of the layer to the global list 'features0'
    features0.append(output.clone())
features1=[]
def hook_function1(module, input, output):
    # This function saves the output of the layer to the global list 'features1'
    features1.append(output.clone())

def generate_ordered_labels(n_classes, labels_per_class):
    # Create a tensor of labels from 0 to n_classes - 1, each repeated repeats_per_class times
    labels = torch.arange(n_classes).repeat_interleave(labels_per_class)
    return labels

def generate_sorted_input_pdf(batch_size, n_classes, nz, samples_per_class=10, device=None):
    # Generate noise
    noise = torch.randn(batch_size, nz,1,1, device=device)

    # Ensure enough samples to select exactly 'samples_per_class' per class
    initial_batch_size = 250
    input_pdf_large = F.softmax(torch.rand(initial_batch_size, n_classes, device=device), dim=1)

    # Sort input_pdf based on argmax values to evenly distribute and order classes
    set_labels_large = torch.argmax(input_pdf_large, dim=1)
    sorted_indices = torch.argsort(set_labels_large)
    ordered_input_pdf = input_pdf_large[sorted_indices]

    # Ensure we pick exactly 'samples_per_class' for each class
    input_pdf = torch.zeros((batch_size, n_classes), device=device)
    for i in range(n_classes):
        indices = (set_labels_large == i).nonzero(as_tuple=True)[0][:samples_per_class]
        input_pdf[i * samples_per_class:(i + 1) * samples_per_class] = input_pdf_large[indices]

    return noise, input_pdf

# Example usage:
batch_size = 100  # 10 classes * 10 samples each
n_classes = 10
nz = 100  # Example size for the noise dimension
noise, input_pdf = generate_sorted_input_pdf(batch_size, n_classes, nz)

print("Noise Shape:", noise.shape)
print("Input PDF Shape:", input_pdf)
print("Input PDF Shape:", input_pdf.shape)
print("Set Labels (Sorted):", torch.argmax(input_pdf, dim=1))

def generate_ordered_one_hot_noise(batch_size, n_classes, nz, samples_per_class=10, device=None):
    # Generate noise
    noise = torch.randn(batch_size, nz, 1, 1, device=device)

    # Generate one-hot labels in order from 0 to n_classes-1
    labels = torch.arange(n_classes).repeat_interleave(samples_per_class).to(device)
    one_hot_labels = torch.nn.functional.one_hot(labels, num_classes=n_classes).float()

    return noise, one_hot_labels

def weights_initialization_gen_xavier(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.xavier_normal_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

def weights_initialization_gen_ortho(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.orthogonal_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

def weights_initialization_gen_normal(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.normal_(m.weight, mean=0.0, std=0.02)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

def weights_initialization_gen_uniform(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.uniform_(m.weight, -0.08, 0.08)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

def cosine_similarity_loss(features):
    normalized_features = F.normalize(features, p=2, dim=1)
    similarity_matrix = torch.mm(normalized_features, normalized_features.t())
    mask = torch.eye(similarity_matrix.size(0), device=similarity_matrix.device).bool()
    similarity_matrix = similarity_matrix.masked_fill(mask, 0)
    loss = similarity_matrix.sum() / (features.size(0) * (features.size(0) - 1))
    return loss  # Minimize

def feature_orthogonality_loss(features):
    gram_matrix = torch.mm(features, features.t())
    identity_matrix = torch.eye(gram_matrix.size(0), device=gram_matrix.device)
    loss = torch.mean((gram_matrix - identity_matrix) ** 2)
    return loss / (features.size(0) * features.size(1))  # Minimize

def kl_divergence(p, q):

    #p = F.softmax(p, dim=1)
    #q = F.softmax(q, dim=1)

    kl_div = F.kl_div(p.log(), q, reduction='batchmean')

    return kl_div

def add_l1_perturbation(images, perturbation_bound):
    # Generate random perturbation
    perturbation = torch.randn_like(images)

    # Normalize the perturbation to have an L1 norm of 1
    perturbation = perturbation / perturbation.abs().sum(dim=[1, 2, 3], keepdim=True)

    # Scale perturbation by the L1 bound
    perturbation = perturbation * perturbation_bound

    # Add the perturbation to the images
    perturbed_images = images + perturbation

    return perturbed_images

def add_l2_perturbation(images, perturbation_bound):
    # Generate random perturbation
    perturbation = torch.randn_like(images)

    # Normalize the perturbation to have an L2 norm of 1
    perturbation = perturbation / perturbation.view(perturbation.size(0), -1).norm(p=2, dim=1).view(-1, 1, 1, 1)

    # Scale perturbation by the L2 bound
    perturbation = perturbation * perturbation_bound

    # Add the perturbation to the images
    perturbed_images = images + perturbation

    return perturbed_images

def add_linf_perturbation(images, perturbation_bound):
    # Generate random perturbation
    perturbation = torch.randn_like(images)

    # Scale the perturbation so that its maximum absolute value does not exceed the perturbation bound
    perturbation = perturbation_bound * torch.sign(perturbation)

    # Add the perturbation to the images
    perturbed_images = images + perturbation

    return perturbed_images

def total_variation_loss(generated_images):
    """
    Computes the Total Variation Loss for a batch of generated images.

    Parameters:
    generated_images (torch.Tensor): A batch of generated images of shape (batch_size, channels, height, width).

    Returns:
    torch.Tensor: The total variation loss.
    """
    batch_size = generated_images.size(0)
    h_variation = torch.pow(generated_images[:, :, 1:, :] - generated_images[:, :, :-1, :], 2).sum()
    w_variation = torch.pow(generated_images[:, :, :, 1:] - generated_images[:, :, :, :-1], 2).sum()

    return (h_variation + w_variation) / batch_size

import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

def save_tsne_plot(features, labels, epoch, save_dir='MNIST-Inversion/fin9/tsne'):
    # Ensure the save directory exists
    os.makedirs(save_dir, exist_ok=True)

    # Convert the features and labels to numpy arrays
    features_np = np.array(features)
    labels_np = np.array(labels)
    # Apply t-SNE to reduce dimensionality to 2D
    tsne = TSNE(n_components=2, random_state=42)
    tsne_results = tsne.fit_transform(features_np)

    # Create a scatter plot
    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=labels_np, cmap='tab10', alpha=0.6)
    plt.colorbar(scatter)
    plt.title(f"t-SNE Plot at Epoch {epoch + 1}")
    plt.xlabel("t-SNE Dimension 1")
    plt.ylabel("t-SNE Dimension 2")

    # Save the plot
    save_path = os.path.join(save_dir, f"tsne_epoch_{epoch + 1}.png")
    plt.savefig(save_path)
    plt.close()

    print(f"t-SNE plot saved at: {save_path}")

from sklearn.decomposition import PCA

def save_pca_plot(features, labels, epoch, save_dir='MNIST-Inversion/fin9/pca'):
    # Ensure the save directory exists
    os.makedirs(save_dir, exist_ok=True)

    # Convert the features and labels to numpy arrays
    features_np = np.array(features)
    labels_np = np.array(labels)

    # Apply PCA to reduce dimensionality to 2D
    pca = PCA(n_components=2)
    pca_results = pca.fit_transform(features_np)

    # Create a scatter plot
    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(pca_results[:, 0], pca_results[:, 1], c=labels_np, cmap='tab10', alpha=0.6)
    plt.colorbar(scatter)
    plt.title(f"PCA Plot at Epoch {epoch + 1}")
    plt.xlabel("PCA Component 1")
    plt.ylabel("PCA Component 2")

    # Save the plot
    save_path = os.path.join(save_dir, f"pca_epoch_{epoch + 1}.png")
    plt.savefig(save_path)
    plt.close()

    print(f"PCA plot saved at: {save_path}")

"""Inversion"""

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_normal)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.01, weight_decay=5e-2)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 5e-3

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  (  60*cosine_similarilty
              + 60*orthogonality_loss
              + 30*cross_entropy
              + 5*kl_divergence_value
               + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"MNIST-Inversion/new1/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_uniform)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.075, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.01)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  (  6000*cosine_similarilty
              + 10*orthogonality_loss
             + 300*cross_entropy
              + 50*kl_divergence_value
              + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"MNIST-Inversion/new2/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_normal)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.05, weight_decay=5e-4)

mlp = LastLayers(ncf).to(device)
copy_weights(csf, mlp)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 5e-4

num_epochs =1000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  (  60*cosine_similarilty
             + 5*orthogonality_loss
             + 30*cross_entropy
             + 5*kl_divergence_value
            )

    loss.backward()
    gen_optimizer.step()

    if epoch % 100 == 0:
        selected_features = features0[0].cpu().detach().numpy()
        all_labels = predicted_labels.cpu().detach().numpy()
        save_tsne_plot(selected_features, all_labels, epoch, save_dir='MNIST-Inversion/fin9/tsne')
        save_pca_plot(selected_features, all_labels, epoch, save_dir='MNIST-Inversion/fin9/pca')

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"MNIST-Inversion/fin9/images/image_{epoch + 1}.png", nrow=10, normalize=True)

"""Reconstruction"""

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_normal)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.05, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.01)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

perturbation_bound = 1.95  # Set your overall perturbation bound

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    var_loss=total_variation_loss(gen_images)

    epsilon = torch.rand(1).item() * perturbation_bound
    perturbation = epsilon * torch.sign(torch.randn_like(gen_images))
    perturbed_images = gen_images + perturbation

    #perturbed_images = add_l1_perturbation(gen_images, perturbation_bound)
    #perturbed_images = add_l2_perturbation(gen_images, perturbation_bound)
    #perturbed_images = add_linf_perturbation(gen_images, perturbation_bound)

    csf_outputs = csf(perturbed_images)
    perturbed_pdf = F.softmax(csf_outputs, dim=1)

    perturbation_loss = criterion(csf_outputs, set_labels)

    predicted_labels = torch.argmax(perturbed_pdf, dim=1)
    perturbation_accuracy = (predicted_labels == set_labels).float().mean()

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    perturbed_kl_divergence_value = kl_divergence(perturbed_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  (  7000*cosine_similarilty
              + 10*orthogonality_loss
             + 1000*cross_entropy
              + 500*kl_divergence_value
              + lambda_l1*l1_regularization
               + 1000*perturbation_loss
               + 500*perturbed_kl_divergence_value
               + 50*var_loss
            )


    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, VL:{var_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f},  PKLD:{perturbed_kl_divergence_value.item():.4f},  PE:{perturbation_loss.item():.4f}, CE: {cross_entropy.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}  PA: {perturbation_accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"MNIST-Inversion/new3/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_normal)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.01, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.05)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

perturbation_bound = 1.95  # Set your overall perturbation bound

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    var_loss=total_variation_loss(gen_images)

    epsilon = torch.rand(1).item() * perturbation_bound
    perturbation = epsilon * torch.sign(torch.randn_like(gen_images))
    perturbed_images = gen_images + perturbation

    perturbed_images = add_l1_perturbation(gen_images, perturbation_bound)
    perturbed_images = add_l2_perturbation(gen_images, perturbation_bound)
    perturbed_images = add_linf_perturbation(gen_images, perturbation_bound)

    csf_outputs = csf(perturbed_images)
    perturbed_pdf = F.softmax(csf_outputs, dim=1)

    perturbation_loss = criterion(csf_outputs, set_labels)

    predicted_labels = torch.argmax(perturbed_pdf, dim=1)
    perturbation_accuracy = (predicted_labels == set_labels).float().mean()

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    perturbed_kl_divergence_value = kl_divergence(perturbed_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  (  10000*cosine_similarilty
              + 10*orthogonality_loss
             + 400*cross_entropy
              + 500*kl_divergence_value
              + lambda_l1*l1_regularization
               + 1000*perturbation_loss
               + 1000*perturbed_kl_divergence_value
               + 40*var_loss
            )


    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, VL:{var_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f},  PKLD:{perturbed_kl_divergence_value.item():.4f},  PE:{perturbation_loss.item():.4f}, CE: {cross_entropy.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}  PA: {perturbation_accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"MNIST-Inversion/new4/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_normal)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.05, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.05)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

perturbation_bound = 0.5  # Set your overall perturbation bound

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    var_loss=total_variation_loss(gen_images)

    perturbed_images = add_l2_perturbation(gen_images, perturbation_bound)
    #epsilon = torch.rand(1).item() * perturbation_bound
    #perturbation = epsilon * torch.sign(torch.randn_like(gen_images))
    #perturbed_images = gen_images + perturbation

    csf_outputs = csf(perturbed_images)
    perturbed_pdf = F.softmax(csf_outputs, dim=1)

    perturbation_loss = criterion(csf_outputs, set_labels)

    predicted_labels = torch.argmax(perturbed_pdf, dim=1)
    perturbation_accuracy = (predicted_labels == set_labels).float().mean()

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    perturbed_kl_divergence_value = kl_divergence(perturbed_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  (  10000*cosine_similarilty
              + 1000*cross_entropy
              + 500*kl_divergence_value
              + lambda_l1*l1_regularization
               + 300*perturbation_loss
               + 300*perturbed_kl_divergence_value
               + 100*var_loss
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, VL:{var_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f},  PKLD:{perturbed_kl_divergence_value.item():.4f},  PE:{perturbation_loss.item():.4f}, CE: {cross_entropy.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}  PA: {perturbation_accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"MNIST-Inversion/new5/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_normal)
#gen.apply(weights_initialization_gen_ortho)
#gen.apply(weights_initialization_gen_xavier)
#gen.apply(weights_initialization_gen_uniform)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.02, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.05)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

perturbation_bound = 3  # Set your overall perturbation bound

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    var_loss=total_variation_loss(gen_images)

    perturbed_images = add_linf_perturbation(gen_images, perturbation_bound)
    #epsilon = torch.rand(1).item() * perturbation_bound
    #perturbation = epsilon * torch.sign(torch.randn_like(gen_images))
    #perturbed_images = gen_images + perturbation

    csf_outputs = csf(perturbed_images)
    perturbed_pdf = F.softmax(csf_outputs, dim=1)

    perturbation_loss = criterion(csf_outputs, set_labels)

    predicted_labels = torch.argmax(perturbed_pdf, dim=1)
    perturbation_accuracy = (predicted_labels == set_labels).float().mean()

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    perturbed_kl_divergence_value = kl_divergence(perturbed_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  (  10000*cosine_similarilty
              + 1000*cross_entropy
              + 500*kl_divergence_value
              + lambda_l1*l1_regularization
               + 300*perturbation_loss
               + 300*perturbed_kl_divergence_value
               + 200*var_loss
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, VL:{var_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f},  PKLD:{perturbed_kl_divergence_value.item():.4f},  PE:{perturbation_loss.item():.4f}, CE: {cross_entropy.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}  PA: {perturbation_accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"MNIST-Inversion/new6/image_{epoch + 1}.png", nrow=10, normalize=True)

"""Iterative Refinement"""

def inversion(num_steps, gen, gen_optimizer, csf, criterion, device, nz, n_classes, epoch):
    # Create a directory if it doesn't exist
    ood_save_dir = 'Downloads/MNISTX/train/ood'
    os.makedirs(ood_save_dir, exist_ok=True)
    gen.train()
    ibar = tqdm(range(num_steps), desc="Inversion")
    # Wrap the loop with tqdm
    for step in ibar:
        gen_optimizer.zero_grad()
        gen.train()

        noise = torch.randn(5000, nz,1,1).to(device)
        input_pdf = F.softmax(torch.randn(5000, n_classes).to(device), dim=1)
        set_labels = torch.argmax(input_pdf, dim=1)

        # Pass noise and labels through the generator
        gen_images = gen(noise, input_pdf)
        hook0 = csf.main[9].register_forward_hook(hook_function0)
        hook1 = csf.main[7].register_forward_hook(hook_function1)

        csf.eval()
        csf_outputs = csf(gen_images)
        output_pdf = F.softmax(csf_outputs, dim=1)

        kl_divergence_value = kl_divergence(output_pdf, input_pdf)
        cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
        orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

        cross_entropy = criterion(csf_outputs, set_labels)
        predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
        accuracy = (predicted_labels == set_labels).float().mean()

        inversion_loss =  (  100*cosine_similarilty
                + 5*orthogonality_loss
                + 30*cross_entropy
                + 5*kl_divergence_value
                )

        inversion_loss.backward()
        gen_optimizer.step()

        hook0.remove()
        hook1.remove()
        features0.clear()
        features1.clear()

        print(f"\nStep {step + 1}/{num_steps}, IL:{inversion_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

        with torch.no_grad():
            fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
            vutils.save_image(fixed_gen_images, f"MNIST-Generation/fin2/epoch_{epoch}_image_{step + 1}.png", nrow=10, normalize=True)

        ibar.set_postfix({"Inversion Loss": inversion_loss.item()})
        # Save generated images for visualization
        # with torch.no_grad():
    #vutils.save_image(gen_images[0:100].detach(), f"ISS-MNIST/Method_1/11_class_epoch_{epoch}.png", nrow=10, normalize=True)

        # Save individual gen_images in Downloads/mnist_extra/training/ood
    for i, image in enumerate(gen_images[0:5000]):
        filename = os.path.join(ood_save_dir, f"gen_{epoch}_{i + 1}.png")
        vutils.save_image(image, filename, normalize=True)

    # Return the last inversion loss and accuracy
    return inversion_loss.item(), accuracy.item()

class Classifier(nn.Module):
    def __init__(self, nc, ncf):
        super(Classifier, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(nc, ncf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ncf),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ncf, ncf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ncf * 2),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ncf * 2, ncf * 4, 3, 1, 0, bias=False),
            nn.Flatten(),
            nn.Linear(ncf * 100, ncf * 2),
            nn.ReLU(),

            nn.Linear(ncf * 2, 11)
        )

    def forward(self, input):
        return self.main(input)

def calculate_class_weights(dataset):
    # Convert the list of targets to a tensor
    targets_tensor = torch.tensor(dataset.targets)

    # Calculate class weights
    class_counts = torch.bincount(targets_tensor)
    total_samples = len(dataset)

    # Calculate class weights
    class_weights = total_samples / class_counts
    class_weights /= torch.sum(class_weights)

    return class_weights

n_classes=11
labels_per_class=10
fixed_batch_size=110

criterion = nn.CrossEntropyLoss()

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(fixed_batch_size, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

csf = Classifier(nc, ncf).to(device)
gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_normal)

gen.train(), csf.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.01, weight_decay=0)
csf_optimizer = optim.Adam(csf.parameters(), lr=0.0001, weight_decay=0)

# Lists to store the training and testing loss and accuracy values
train_losses = []
train_accuracies = []
test_losses = []
test_accuracies = []
inversion_losses = []
inversion_accuracies = []

# Initialize variables to track the best test accuracy and associated epoch
best_test_accuracy = 0.0
best_epoch = 0
class_weights = calculate_class_weights(train_dataset).to(device)
csf_criterion = nn.CrossEntropyLoss(weight=class_weights)

# Training loop for 10 epochs
num_steps =500
num_epochs = 25
for epoch in range(0,num_epochs):
    # Training
    train_loss, train_accuracy = train(csf, train_loader, csf_optimizer, csf_criterion, device)
    train_losses.append(train_loss)
    train_accuracies.append(train_accuracy)

    # Testing
    test_loss, test_accuracy = test(csf, test_loader, device)
    test_losses.append(test_loss)
    test_accuracies.append(test_accuracy)

    #gen = Generator(nz, ngf, nc, n_classes).to(device)
    #gen.train()
    #gen_optimizer = optim.Adam(gen.parameters(), lr=0.001)

    # Inversion
    inversion_loss, inversion_accuracy = inversion(num_steps, gen, gen_optimizer, csf, criterion, device, nz, n_classes, epoch + 1)
    inversion_losses.append(inversion_loss)
    inversion_accuracies.append(inversion_accuracy)

    # Redefine the dataset, dataloader, class weights, csf_criterion
    train_dataset = ImageFolder(root=train_data_dir, transform=train_transform)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)
    class_weights = calculate_class_weights(train_dataset).to(device)

    # Define CrossEntropyLoss with weights
    csf_criterion = nn.CrossEntropyLoss(weight=class_weights)

    print(f"\nEpoch {epoch + 1}/{num_epochs}")
    print(f"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}")
    print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")
    print(f"Inversion Loss: {inversion_loss:.4f}, Inversion Accuracy: {inversion_accuracy:.4f}\n")


    # Check if the current test_accuracy is the best so far
    if test_accuracy > best_test_accuracy:
        best_test_accuracy = test_accuracy
        best_epoch = epoch + 1  # Store the epoch number of the best accuracy
        # Save the model
        torch.save(csf.state_dict(), f'best_csf_model_epoch_{best_epoch}.pth')
        print(f"New best test accuracy: {best_test_accuracy:.4f} at epoch {best_epoch}. Model saved.")

# Print the overall best accuracy and epoch after training is complete
print(f"Best Test Accuracy: {best_test_accuracy:.4f} at Epoch {best_epoch}")

