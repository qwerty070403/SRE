# -*- coding: utf-8 -*-
"""Copy of FMNIST Network Inversion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cw_mWsGpnxwoDQy6rS5ly8w5c0sOzgFF
"""

import os
import cv2
import glob
import torch
import numpy as np
from PIL import Image
import torch.nn as nn
from tqdm import tqdm
import torch.optim as optim
import torchvision.utils as vutils
import torch.nn.functional as F
import matplotlib.pyplot as plt
from torchvision import transforms
from torch.utils.data import Dataset
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms.functional as TF
from sklearn.preprocessing import MinMaxScaler
from torchvision.datasets import ImageFolder

import os
import torch
import torchvision
import torchvision.transforms as transforms

# Create directories if they don't exist
train_data_dir = 'Downloads/Fashion_MNIST/Train'
test_data_dir = 'Downloads/Fashion_MNIST/Test'

os.makedirs(train_data_dir, exist_ok=True)
os.makedirs(test_data_dir, exist_ok=True)

# Set device (CPU or GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define transformation (optional, but recommended)
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])

# Download and save the training dataset in the specified directory
train_data = torchvision.datasets.FashionMNIST(
    root=train_data_dir,
    train=True,
    download=True,
    transform=transform
)

# Download and save the test dataset in the specified directory
test_data = torchvision.datasets.FashionMNIST(
    root=test_data_dir,
    train=False,
    download=True,
    transform=transform
)

# Data loaders
train_loader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)

print("Datasets downloaded and loaded.")

# Define the path to your MNIST dataset
train_data_dir = 'Downloads/Fashion_MNIST/Train'
test_data_dir = 'Downloads/Fashion_MNIST/Test'

# Set device (CPU or GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

import torch
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import torchvision.datasets as datasets

# Mean and std of Fashion MNIST
fashion_mnist_mean = 0.2861052180872351
fashion_mnist_std = 0.3528112273926318
batch_size = 100

# Define data transformations for training and testing
train_transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize(28),
    transforms.ToTensor(),
    transforms.Normalize((fashion_mnist_mean,), (fashion_mnist_std,))
])

test_transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize(28),
    transforms.ToTensor(),
    transforms.Normalize((fashion_mnist_mean,), (fashion_mnist_std,))
])

# Load the Fashion MNIST dataset directly from torchvision
train_dataset = datasets.FashionMNIST(root='data', train=True, download=True, transform=train_transform)
test_dataset = datasets.FashionMNIST(root='data', train=False, download=True, transform=test_transform)

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)

print("Fashion MNIST dataset loaded successfully.")

print("Training Dataset:")
print(f"  Size: {len(train_dataset)}")
print(f"  Shape: {next(iter(train_loader))[0].shape}")
print(f"  Batch Size: {train_loader.batch_size}")

print("\nTesting Dataset:")
print(f"  Size: {len(test_dataset)}")
print(f"  Shape: {next(iter(test_loader))[0].shape}")
print(f"  Batch Size: {test_loader.batch_size}")

import os
import cv2
import matplotlib.pyplot as plt

# Dictionary to store images for each class
class_images = {}

# Traverse through the folder and collect images
for class_name in sorted(os.listdir(train_data_dir)):
    class_path = os.path.join(train_data_dir, class_name)

    # Ensure that the path is a directory
    if os.path.isdir(class_path):
        class_images[class_name] = []

        # Iterate through images in the class folder, load only 10 images per class
        for image_file in os.listdir(class_path)[:10]:
            image_path = os.path.join(class_path, image_file)
            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

            # Check if the image was loaded correctly
            if image is not None:
                class_images[class_name].append(image)
            else:
                print(f"Warning: Failed to load image {image_path}")

# Plot 10x10 grid
fig, axs = plt.subplots(len(class_images), 11, figsize=(10, len(class_images)))

# Plot images in grid
for i, (class_name, images) in enumerate(class_images.items()):
    for j in range(10):
        if j < len(images):
            axs[i, j].imshow(images[j], cmap="gray")
        axs[i, j].axis("off")

    # Display class name in the last column
    axs[i, 10].text(0.5, 0.5, class_name, fontsize=8, ha='center', va='center')
    axs[i, 10].axis("off")

plt.show()

"""Classifier"""

class Classifier(nn.Module):
    def __init__(self, nc, ncf):
        super(Classifier, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(nc, ncf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ncf),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ncf, ncf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ncf * 2),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ncf * 2, ncf * 4, 3, 1, 0, bias=False),
            nn.Flatten(),
            nn.Linear(ncf * 100, ncf * 2),
            nn.ReLU(),

            nn.Linear(ncf * 2, 10)
        )

    def forward(self, input):
        return self.main(input)

class Generator(nn.Module):
    def __init__(self, nz, ngf, nc=1, n_classes=10):  # Default nc=1 for grayscale output, n_classes=10
        super(Generator, self).__init__()
        self.nz = nz
        self.n_classes = n_classes

        # Define the embedding layer for class matrix diagonal
        self.embedding = nn.Linear(n_classes, nz)

        # Adjust layers before concatenation to take nz*2 channels
        self.layers_before_concat = nn.Sequential(
            nn.ConvTranspose2d(nz * 2, ngf, 4, 1, 0),  # Adjusted input channels to nz*2
            nn.BatchNorm2d(ngf),
            #nn.Dropout2d(0.1),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf, ngf * 2, 4, 1, 0),
            nn.BatchNorm2d(ngf * 2),
            #nn.Dropout2d(0.1),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 2, ngf * 4, 4, 1, 0),
            nn.BatchNorm2d(ngf * 4),
            #nn.Dropout2d(0.1),
            nn.ReLU(True),
        )

        # Layers after concatenation remain the same
        self.layers_after_concat = nn.Sequential(
            nn.ConvTranspose2d(ngf * 4 + 1, ngf * 8, 4, 1, 1),
            nn.BatchNorm2d(ngf * 8),
            nn.Dropout2d(0.1),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 1, 1),
            nn.BatchNorm2d(ngf * 4),
            nn.Dropout2d(0.1),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1),
            nn.BatchNorm2d(ngf * 2),
            nn.Dropout2d(0.1),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 2, ngf, 4, 1, 0),
            nn.BatchNorm2d(ngf),
            nn.Dropout2d(0.1),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf, nc, 4, 1, 1),
            nn.Tanh(),
        )

    def forward(self, latent_vector, conditioning_vector):
        # Get the argmax of the conditioning vector
        argmax_index = torch.argmax(conditioning_vector, dim=1)

        # Create a class matrix based on the argmax index
        class_matrix = torch.zeros((latent_vector.size(0), self.n_classes, self.n_classes)).to(latent_vector.device)
        for i, idx in enumerate(argmax_index):
            class_matrix[i, idx, :] = 1
            class_matrix[i, :, idx] = 1

        # Map the conditioning vector to nz dimensions
        embedding_vector = self.embedding(conditioning_vector).unsqueeze(2).unsqueeze(3)

        # Concatenate the latent vector with the conditioned input
        concat1 = torch.cat([latent_vector, embedding_vector], dim=1)

        # Pass the combined input through the layers before concatenation
        upsample1 = self.layers_before_concat(concat1)

        # Ensure class_matrix has the correct shape for concatenation
        class_matrix = class_matrix.unsqueeze(1)

        # Concatenate the upsampled noise with the class matrix
        concat2 = torch.cat([upsample1, class_matrix], dim=1)

        # Pass through the layers after concatenation to generate the output
        upsample2 = self.layers_after_concat(concat2)

        return upsample2

class Generator(nn.Module):
    def __init__(self, nz, ngf, nc, n_classes):
        super(Generator, self).__init__()
        # Linear layer to map the softmaxed vector to the size nz
        self.embed = nn.Linear(n_classes, nz)

        # The main model architecture remains unchanged
        self.main = nn.Sequential(
            nn.ConvTranspose2d(nz * 2, ngf * 4, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 4),
            #nn.Dropout2d(0.2),
            nn.Dropout2d(0.3),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            #nn.Dropout2d(0.2),
            nn.Dropout2d(0.3),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 2, bias=False),
            nn.BatchNorm2d(ngf),
            #nn.Dropout2d(0.2),
            nn.Dropout2d(0.3),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, z, class_vector):
        # Map the class vector to the latent space size
        embed_vector = self.embed(class_vector).unsqueeze(-1).unsqueeze(-1)
        # Concatenate with the latent vector z
        input = torch.cat([z, embed_vector], 1)
        return self.main(input)

# Example usage:
nz = 100
ngf = 64
nc = 1
n_classes = 10
ncf = 64

# Instantiate the generator and classifier
gen = Generator(nz, ngf, nc, n_classes)
csf = Classifier(nc, ncf)

# Random latent vector
latent_vector = torch.randn((5, nz,1,1))

# Define the conditioning random vector
n_dim_random_vector = torch.randn((5, n_classes))
print("Random vector:", n_dim_random_vector)

# Apply softmax to the random vector
conditioning_vector = F.softmax(n_dim_random_vector, dim=1)
print("Softmaxed vector:", conditioning_vector)

# Generate image
generated_image = gen(latent_vector, conditioning_vector)
print("Generated image shape:", generated_image.shape)

# Pass the generated image through the classifier
classifier_output = csf(generated_image)
print("Classifier output shape:", classifier_output.shape)

def train(model, train_loader, optimizer, criterion, device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc="Training")

    for i, (inputs, labels) in pbar:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        pbar.set_postfix({"Batch Loss": loss.item()})

    average_loss = running_loss / len(train_loader)
    accuracy = correct / total

    return average_loss, accuracy

def test(model, test_loader, device):
    model.eval()
    correct = 0
    total = 0
    running_loss = 0.0

    with torch.no_grad():
        pbar = tqdm(enumerate(test_loader), total=len(test_loader), desc="Testing")

        for i, (inputs, labels) in pbar:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            running_loss += loss.item()

            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            pbar.set_postfix({"Batch Loss": loss.item()})

    average_loss = running_loss / len(test_loader)
    accuracy = correct / total

    return average_loss, accuracy

# Classifier Hyperparameters
ncf = 64  # Number of classifier filters
nc = 1    # Number of channels in the input images (1 for grayscale)

# Initialize your model, optimizer, and criterion
csf = Classifier(nc, ncf).to(device)

csf_optimizer = optim.Adam(csf.parameters(), lr=0.0005)
criterion = nn.CrossEntropyLoss()

# Lists to store the training and testing loss and accuracy values
train_losses = []
train_accuracies = []
test_losses = []
test_accuracies = []

# Variable to store the best test accuracy
best_test_accuracy = 0.0
best_model_state = None

# Training loop for 10 epochs
num_epochs = 25
for epoch in range(num_epochs):
    # Training
    train_loss, train_accuracy = train(csf, train_loader, csf_optimizer, criterion, device)
    train_losses.append(train_loss)
    train_accuracies.append(train_accuracy)

    # Testing
    test_loss, test_accuracy = test(csf, test_loader, device)
    test_losses.append(test_loss)
    test_accuracies.append(test_accuracy)

    # Check if this is the best model so far
    if test_accuracy > best_test_accuracy:
        best_test_accuracy = test_accuracy
        best_model_state = csf.state_dict()

    print(f"\nEpoch {epoch + 1}/{num_epochs}")
    print(f"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}")
    print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")

# Save the best model
if best_model_state is not None:
    torch.save(best_model_state, 'FashionMNIST-Inversion/fmnist_csf_10_wo_aug.pth')
    print(f"Best model saved with test accuracy: {best_test_accuracy:.4f}")
else:
    print("No model was saved.")

criterion=nn.CrossEntropyLoss()
csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_wo_aug.pth'))
test_loss, test_acc = test(csf,test_loader,device)
print("\nTest Accuracy: ",test_acc)

features0=[]
def hook_function0(module, input, output):
    # This function saves the output of the layer to the global list 'features0'
    features0.append(output.clone())
features1=[]
def hook_function1(module, input, output):
    # This function saves the output of the layer to the global list 'features1'
    features1.append(output.clone())

def generate_ordered_labels(n_classes, labels_per_class):
    # Create a tensor of labels from 0 to n_classes - 1, each repeated repeats_per_class times
    labels = torch.arange(n_classes).repeat_interleave(labels_per_class)
    return labels

def generate_sorted_input_pdf(batch_size, n_classes, nz, samples_per_class=10, device=None):
    # Generate noise
    noise = torch.randn(batch_size, nz,1,1, device=device)

    # Ensure enough samples to select exactly 'samples_per_class' per class
    initial_batch_size = 250
    input_pdf_large = F.softmax(torch.rand(initial_batch_size, n_classes, device=device), dim=1)

    # Sort input_pdf based on argmax values to evenly distribute and order classes
    set_labels_large = torch.argmax(input_pdf_large, dim=1)
    sorted_indices = torch.argsort(set_labels_large)
    ordered_input_pdf = input_pdf_large[sorted_indices]

    # Ensure we pick exactly 'samples_per_class' for each class
    input_pdf = torch.zeros((batch_size, n_classes), device=device)
    for i in range(n_classes):
        indices = (set_labels_large == i).nonzero(as_tuple=True)[0][:samples_per_class]
        input_pdf[i * samples_per_class:(i + 1) * samples_per_class] = input_pdf_large[indices]

    return noise, input_pdf

# Example usage:
batch_size = 100  # 10 classes * 10 samples each
n_classes = 10
nz = 100  # Example size for the noise dimension
noise, input_pdf = generate_sorted_input_pdf(batch_size, n_classes, nz)

print("Noise Shape:", noise.shape)
#print("Input PDF Shape:", input_pdf)
print("Input PDF Shape:", input_pdf.shape)
print("Set Labels (Sorted):", torch.argmax(input_pdf, dim=1))

def generate_ordered_one_hot_noise(batch_size, n_classes, nz, samples_per_class=10, device=None):
    # Generate noise
    noise = torch.randn(batch_size, nz, 1, 1, device=device)

    # Generate one-hot labels in order from 0 to n_classes-1
    labels = torch.arange(n_classes).repeat_interleave(samples_per_class).to(device)
    one_hot_labels = torch.nn.functional.one_hot(labels, num_classes=n_classes).float()

    return noise, one_hot_labels

def weights_initialization_gen_xavier(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.xavier_normal_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.Linear):  # For the embedding layer
        nn.init.xavier_normal_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)

def weights_initialization_gen_ortho(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.orthogonal_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.Linear):  # For the embedding layer
        nn.init.orthogonal_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)

def weights_initialization_gen_normal(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.normal_(m.weight, mean=0.0, std=0.02)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.Linear):  # For the embedding layer
        nn.init.normal_(m.weight, mean=0.0, std=0.02)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)

def weights_initialization_gen_uniform(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.uniform_(m.weight, -0.08, 0.08)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.Linear):  # For the embedding layer
        nn.init.uniform_(m.weight, -0.08, 0.08)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)

def weights_initialization_gen_zero(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.constant_(m.weight, 0)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 0)
        nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.Linear):  # For the embedding layer
        nn.init.constant_(m.weight, 0)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)

def weights_initialization_gen_small(m, scale=1):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.constant_(m.weight, scale)
        if m.bias is not None:
            nn.init.constant_(m.bias, scale)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, scale)
        nn.init.constant_(m.bias, scale)
    elif isinstance(m, nn.Linear):  # For the embedding layer
        nn.init.constant_(m.weight, scale)
        if m.bias is not None:
            nn.init.constant_(m.bias, scale)

def weights_initialization_gen_custom(m):
    if isinstance(m, nn.ConvTranspose2d):
        # Xavier initialization for ConvTranspose2d layers
        nn.init.normal_(m.weight, mean=0.0, std=0.02)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        # Constant initialization for BatchNorm2d layers
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.Linear):
        # Orthogonal initialization for Linear (embedding) layers
        nn.init.orthogonal_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)

def cosine_similarity_loss(features):
    normalized_features = F.normalize(features, p=2, dim=1)
    similarity_matrix = torch.mm(normalized_features, normalized_features.t())
    mask = torch.eye(similarity_matrix.size(0), device=similarity_matrix.device).bool()
    similarity_matrix = similarity_matrix.masked_fill(mask, 0)
    loss = similarity_matrix.sum() / (features.size(0) * (features.size(0) - 1))
    return loss  # Minimize

def feature_orthogonality_loss(features):
    gram_matrix = torch.mm(features, features.t())
    identity_matrix = torch.eye(gram_matrix.size(0), device=gram_matrix.device)
    loss = torch.mean((gram_matrix - identity_matrix) ** 2)
    return loss / (features.size(0) * features.size(1))  # Minimize

def jensen_shannon_divergence(p, q):

    # Ensure the inputs are probability distributions
    #p = F.softmax(p, dim=1)
    #q = F.softmax(q, dim=1)

    # Compute the midpoint distribution
    m = 0.5 * (p + q)

    # Compute the KL divergence between each distribution and the midpoint
    kl_p_m = F.kl_div(p.log(), m, reduction='batchmean')
    kl_q_m = F.kl_div(q.log(), m, reduction='batchmean')

    # The Jensen-Shannon Divergence is the average of these two KL divergences
    jsd = 0.5 * (kl_p_m + kl_q_m)

    return jsd


def kl_divergence(p, q):

    #p = F.softmax(p, dim=1)
    #q = F.softmax(q, dim=1)

    kl_div = F.kl_div(p.log(), q, reduction='batchmean')

    return kl_div

def quantization_constraint(images, num_levels=256):
    # Scale from [-1, 1] to [0, 1]
    images = (images + 1) / 2.0
    # Scale from [0, 1] to [0, 255]
    images = images * 255.0
    quantized_images = torch.round(images * (num_levels - 1)) / (num_levels - 1)
    return torch.mean((images - quantized_images) ** 2)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_wo_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.05, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.01)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( # 60*cosine_similarilty
             # + 10*orthogonality_loss
             + 300*cross_entropy
             # + 50*kl_divergence_value
              # + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/1/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_wo_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_normal)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.03, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.25)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 6000*cosine_similarilty
             # + 10*orthogonality_loss
             + 300*cross_entropy
             # + 50*kl_divergence_value
              # + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/2/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_wo_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_normal)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.03, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.25)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 6000*cosine_similarilty
             # + 10*orthogonality_loss
             + 300*cross_entropy
             # + 50*kl_divergence_value
              # + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/3/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_wo_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.009, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 6000*cosine_similarilty
              +100*orthogonality_loss
             + 300*cross_entropy
             + 500*kl_divergence_value
              # + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/4/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_wo_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.01, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.01)

n_classes=10
batch_size=512
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 600*cosine_similarilty
              + 10*orthogonality_loss
             + 300*cross_entropy
              + 50*kl_divergence_value
              # + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/5/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_wo_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.005, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.01)

n_classes=10
batch_size=1024
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 10000*cosine_similarilty
              + 600*orthogonality_loss
             + 50*cross_entropy
             + 50*kl_divergence_value
               + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/6/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_with_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.01, weight_decay=5e-4)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.01)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 5e-4

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  (10000*cosine_similarilty
              + 60*orthogonality_loss
             + 100*cross_entropy
             + 100*kl_divergence_value
               + 1*quant_loss
              + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/7/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_with_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.AdamW(gen.parameters(), lr=0.01, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.01)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 6000*cosine_similarilty
              + 60*orthogonality_loss
             + 500*cross_entropy
             + 50*kl_divergence_value
               + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/8/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_with_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.001, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.01)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 6000*cosine_similarilty
              + 60*orthogonality_loss
             + 500*cross_entropy
             + 500*kl_divergence_value
               + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/9/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_with_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.1, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.01)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 25000*cosine_similarilty
              + 600*orthogonality_loss
             + 2500*cross_entropy
             + 100*kl_divergence_value
               + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/10/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_with_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.01, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.01)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 25000*cosine_similarilty
              + 600*orthogonality_loss
             + 2500*cross_entropy
             + 100*kl_divergence_value
               + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/11/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_with_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.01, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 25000*cosine_similarilty
              + 60*orthogonality_loss
             + 1000*cross_entropy
             + 10*kl_divergence_value
               + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/12/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_with_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.05, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 25000*cosine_similarilty
              + 600*orthogonality_loss
             + 2500*cross_entropy
             + 10*kl_divergence_value
               + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/13/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_with_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.05, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 25000*cosine_similarilty
              + 600*orthogonality_loss
             + 2500*cross_entropy
             + 10*kl_divergence_value
               + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/14/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_with_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.05, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 25000*cosine_similarilty
             # + 600*orthogonality_loss
             #+ 2500*cross_entropy
             #+ 10*kl_divergence_value
             #  + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/15/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_with_aug.pth'))

#gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.001, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( #25000*cosine_similarilty
             # + 600*orthogonality_loss
              + cross_entropy
             #+ 10*kl_divergence_value
             #  + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/16/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_with_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.AdamW(gen.parameters(), lr=0.001, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 25*cosine_similarilty
             # + 600*orthogonality_loss
             #+ 2500*cross_entropy
             #+ 10*kl_divergence_value
             #  + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/17/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_with_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_custom)
#gen.train()
gen_optimizer = optim.AdamW(gen.parameters(), lr=0.001, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( cosine_similarilty
             # + 600*orthogonality_loss
             + cross_entropy
             #+ 10*kl_divergence_value
             #  + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/18/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_wo_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.AdamW(gen.parameters(), lr=0.09, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 11111*cosine_similarilty
             # + 600*orthogonality_loss
             #+ cross_entropy
             #+ 10*kl_divergence_value
             #  + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/19/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_with_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.AdamW(gen.parameters(), lr=0.01, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 1000*cosine_similarilty
             # + 600*orthogonality_loss
             + cross_entropy
             #+ 10*kl_divergence_value
             #  + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/20/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_with_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.AdamW(gen.parameters(), lr=0.01, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( cosine_similarilty
             # + 600*orthogonality_loss
             + cross_entropy
             #+ 10*kl_divergence_value
             #  + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/21/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('FashionMNIST-Inversion/fmnist_csf_10_with_aug.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_custom)
gen.train()
gen_optimizer = optim.AdamW(gen.parameters(), lr=0.01, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes=10
batch_size=1000
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    quant_loss = quantization_constraint(gen_images)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  ( 101*cosine_similarilty
             # + 600*orthogonality_loss
             + cross_entropy
             #+ 10*kl_divergence_value
             #  + 1*quant_loss
             # + lambda_l1*l1_regularization
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, QL:{quant_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"FashionMNIST-Inversion/GF/22/image_{epoch + 1}.png", nrow=10, normalize=True)

