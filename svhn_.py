# -*- coding: utf-8 -*-
"""SVHN_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ic8DFoyDLTTeMPBtzrIeih-4BHvlQkvm
"""

import os
import cv2
import glob
import torch
import numpy as np
from PIL import Image
import torch.nn as nn
from tqdm import tqdm
import torch.optim as optim
import torchvision.utils as vutils
import torch.nn.functional as F
import matplotlib.pyplot as plt
from torchvision import transforms
from torch.utils.data import Dataset
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms.functional as TF
from sklearn.preprocessing import MinMaxScaler
from torchvision.datasets import ImageFolder
from torchvision import datasets, transforms

import os
import shutil
from torchvision import datasets
from scipy.io import loadmat
from PIL import Image
import numpy as np

# Define paths
svhn_root = './data/SVHN'
train_data_dir = os.path.join(svhn_root, 'train')
test_data_dir = os.path.join(svhn_root, 'test')

# Make sure the directories exist
os.makedirs(train_data_dir, exist_ok=True)
os.makedirs(test_data_dir, exist_ok=True)

# Download the SVHN dataset using torchvision.datasets
train_set = datasets.SVHN(root=svhn_root, split='train', download=True)
test_set = datasets.SVHN(root=svhn_root, split='test', download=True)

# Class labels in SVHN (Digits 1-10, where '10' represents '0')
class_names = [str(i) for i in range(10)]

# Move train images into class-specific folders
for idx, (image, label) in enumerate(train_set):
    # Convert label '10' to '0' for SVHN
    label = 0 if label == 10 else label
    label_dir = os.path.join(train_data_dir, class_names[label])
    os.makedirs(label_dir, exist_ok=True)
    image.save(os.path.join(label_dir, f"{idx}.png"))  # Save images

# Move test images into class-specific folders
for idx, (image, label) in enumerate(test_set):
    label = 0 if label == 10 else label
    label_dir = os.path.join(test_data_dir, class_names[label])
    os.makedirs(label_dir, exist_ok=True)
    image.save(os.path.join(label_dir, f"{idx}.png"))

# Define the path to your SVHN dataset
train_data_dir = '/content/data/SVHN/train'
test_data_dir = '/content/data/SVHN/test'

# Set device (CPU or GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

import torch
import torchvision
import torchvision.transforms as transforms
from torchvision.datasets import SVHN
from torch.utils.data import DataLoader

batch_size = 128

# Define data transformations for training and testing
train_transform = transforms.Compose([
    transforms.RandomCrop(32, padding=4),  # SVHN images are already 32x32, so no need to resize
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.2, 0.2, 0.2), (0.3, 0.3, 0.3))  # Normalize to match the range of SVHN images
])

test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.2, 0.2, 0.2), (0.3, 0.3, 0.3))
])

# Load the SVHN dataset
train_dataset = SVHN(root='/content/data/SVHN', split='train', download=True, transform=train_transform)
test_dataset = SVHN(root='/content/data/SVHN', split='test', download=True, transform=test_transform)

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)

print("Training Dataset:")
print(f"  Size: {len(train_dataset)}")
print(f"  Shape: {next(iter(train_loader))[0].shape}")
print(f"  Batch Size: {train_loader.batch_size}")

print("\nTesting Dataset:")
print(f"  Size: {len(test_dataset)}")
print(f"  Shape: {next(iter(test_loader))[0].shape}")
print(f"  Batch Size: {test_loader.batch_size}")

import torch
import matplotlib.pyplot as plt

# Dictionary to store images for each class (digits 0-9)
class_labels = [str(i) for i in range(10)]
class_images = {i: [] for i in class_labels}

# Collect 10 images for each class
for images, labels in train_loader:
    for img, lbl in zip(images, labels):
        class_label = str(lbl.item())  # Convert label to string for dictionary keys
        if len(class_images[class_label]) < 10:  # Limit to 10 images per class
            # Denormalize the image for display
            img = img * torch.tensor([0.2, 0.2, 0.2]).view(3, 1, 1) + torch.tensor([0.3, 0.3, 0.3]).view(3, 1, 1)
            class_images[class_label].append(img.permute(1, 2, 0).numpy())  # Convert tensor to NumPy array

    # Stop when we have 10 images per class
    if all(len(class_images[label]) == 10 for label in class_labels):
        break

# Plot a 10x10 grid of images
fig, axs = plt.subplots(10, 10, figsize=(10, 10))

for int_i, class_label in enumerate(class_labels):
    for j in range(10):
        axs[int_i, j].imshow(class_images[class_label][j])
        axs[int_i, j].axis('off')

plt.show()

"""Classifier"""

class Classifier(nn.Module):
    def __init__(self, nc, ncf):
        super(Classifier, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(nc, ncf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ncf),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ncf, ncf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ncf * 2),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ncf * 2, ncf * 4, 3, 1, 0, bias=False),
            nn.Flatten(),
            nn.Linear(ncf * 144, 512 ),
            nn.ReLU(),
            nn.Linear( 512, 10)
        )

    def forward(self, input):
        # print(input.shape)
        return self.main(input)

"""We have defined a CNN here, the output is a 10 element 1D vector with probabilities of possible values the image has between 0 and 9."""

class Generator(nn.Module):
    def __init__(self, nz, ngf, nc, n_classes):
        super(Generator, self).__init__()
        # Linear layer to map the softmaxed vector to the size nz
        self.embed = nn.Linear(n_classes, nz)

        # The main model architecture
        self.main = nn.Sequential(
            nn.ConvTranspose2d(nz * 2, ngf * 4, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.Dropout2d(0.2),
            nn.Dropout2d(0.3),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.Dropout2d(0.2),
            nn.Dropout2d(0.3),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 2, bias=False),
            nn.BatchNorm2d(ngf),
            nn.Dropout2d(0.2),
            nn.Dropout2d(0.3),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, z, class_vector):
        # Map the class vector to the latent space size
        embed_vector = self.embed(class_vector).unsqueeze(-1).unsqueeze(-1)
        print(f"Embedding Vector Shape: {embed_vector.shape}")

        # Concatenate with the latent vector z
        input = torch.cat([z, embed_vector], 1)
        print(f"Input Shape after concatenation: {input.shape}")

        # Pass through main network
        out = input
        for layer in self.main:
            out = layer(out)
            print(f"Output Shape after {layer}: {out.shape}")

        return out

"""The Generator class in this code creates synthetic images by combining a noise vector and a class label vector, using transposed convolutions to upsample the input into a high-resolution image. It also employs batch normalization and dropout to enhance learning and prevent overfitting."""

def weights_initialization_cnn(m):
    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)

"""The weights_initialization_cnn function initializes the weights of convolutional and linear layers using He initialization to promote effective training, especially for ReLU activation functions. It also sets biases to zero if they exist, ensuring a balanced starting point for training."""

def train(model, train_loader, optimizer, criterion, device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc="Training")

    for i, (inputs, labels) in pbar:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        pbar.set_postfix({"Batch Loss": loss.item()})

    average_loss = running_loss / len(train_loader)
    accuracy = correct / total

    return average_loss, accuracy

"""The train function trains a neural network for one epoch, calculating the average loss and accuracy. It handles data transfer to the appropriate device, performs forward and backward passes, updates model parameters, and uses a progress bar to monitor training progress."""

def test(model, test_loader, device):
    model.eval()
    correct = 0
    total = 0
    running_loss = 0.0

    with torch.no_grad():
        pbar = tqdm(enumerate(test_loader), total=len(test_loader), desc="Testing")

        for i, (inputs, labels) in pbar:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            running_loss += loss.item()

            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            pbar.set_postfix({"Batch Loss": loss.item()})

    average_loss = running_loss / len(test_loader)
    accuracy = correct / total

    return average_loss, accuracy

"""The test function evaluates a neural network on the test dataset without updating the model parameters. It calculates the average loss and accuracy, using torch.no_grad() to optimize performance and ensure consistent evaluation behavior."""

# Classifier Hyperparameters
ncf = 64  # Number of classifier filters
nc = 3    # Number of channels in the input images (1 for grayscale)

# Initialize your model, optimizer, and criterion
csf = Classifier(nc, ncf).to(device)
csf.apply(weights_initialization_cnn)

csf_optimizer = optim.Adam(csf.parameters(), lr=0.0001)
criterion = nn.CrossEntropyLoss()

# Lists to store the training and testing loss and accuracy values
train_losses = []
train_accuracies = []
test_losses = []
test_accuracies = []
# Variable to store the best test accuracy
best_test_accuracy = 0.0
best_model_state = None

# Classifier Hyperparameters
ncf = 64  # Number of classifier filters
nc = 3    # Number of channels in the input images (1 for grayscale)

# Initialize your model, optimizer, and criterion
csf = Classifier(nc, ncf).to(device)
csf.apply(weights_initialization_cnn)

csf_optimizer = optim.Adam(csf.parameters(), lr=0.0003)
criterion = nn.CrossEntropyLoss()

# Lists to store the training and testing loss and accuracy values
train_losses = []
train_accuracies = []
test_losses = []
test_accuracies = []

# Variable to store the best test accuracy
best_test_accuracy = 0.0
best_model_state = None

# Training loop for 25 epochs
num_epochs = 30
for epoch in range(num_epochs):
    # Training
    train_loss, train_accuracy = train(csf, train_loader, csf_optimizer, criterion, device)
    train_losses.append(train_loss)
    train_accuracies.append(train_accuracy)

    # Testing
    test_loss, test_accuracy = test(csf, test_loader, device)
    test_losses.append(test_loss)
    test_accuracies.append(test_accuracy)

    # Check if this is the best model so far
    if test_accuracy > best_test_accuracy:
        best_test_accuracy = test_accuracy
        best_model_state = csf.state_dict()

    print(f"\nEpoch {epoch + 1}/{num_epochs}")
    print(f"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}")
    print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")

# Add the following code after the training loop, before saving the model
import os

# Define the directory where you want to save the model
save_dir = 'SVHN-Inversion'

# Create the directory if it doesn't exist
os.makedirs(save_dir, exist_ok=True)

# Save the best model
if best_model_state is not None:
    model_save_path = os.path.join(save_dir, 'svhn_csf_10.pth')
    torch.save(best_model_state, model_save_path)
    print(f"Best model saved with test accuracy: {best_test_accuracy:.4f}")
else:
    print("No model was saved.")

# Plotting accuracies
import matplotlib.pyplot as plt

# Plotting training and testing accuracies
plt.figure(figsize=(10, 6))
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(test_accuracies, label='Testing Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Testing Accuracy over Epochs')
plt.legend()
plt.grid(True)
plt.show()

# Add the following code after the training loop, before saving the model
import os

# Define the directory where you want to save the model
save_dir = 'SVHN'

# Create the directory if it doesn't exist
os.makedirs(save_dir, exist_ok=True)

# Save the best model
if best_model_state is not None:
    model_save_path = os.path.join(save_dir, 'svhn_csf_10.pth')
    torch.save(best_model_state, model_save_path)
    print(f"Best model saved with test accuracy: {best_test_accuracy:.4f}")
else:
    print("No model was saved.")

"""The script trains a classifier model for a specified number of epochs, evaluates it on test data, and tracks performance metrics. It identifies and saves the model with the highest test accuracy."""

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('SVHN/svhn_csf_10.pth' , weights_only = True))

features0=[]
def hook_function0(module, input, output):
    # This function saves the output of the layer to the global list 'features0'
    features0.append(output.clone())
features1=[]
def hook_function1(module, input, output):
    # This function saves the output of the layer to the global list 'features1'
    features1.append(output.clone())

def generate_ordered_labels(n_classes, labels_per_class):
    # Create a tensor of labels from 0 to n_classes - 1, each repeated repeats_per_class times
    labels = torch.arange(n_classes).repeat_interleave(labels_per_class)
    return labels

def generate_sorted_input_pdf(batch_size, n_classes, nz, samples_per_class=10, device=None):
    # Generate noise
    noise = torch.randn(batch_size, nz,1,1, device=device)

    # Ensure enough samples to select exactly 'samples_per_class' per class
    initial_batch_size = 250
    input_pdf_large = F.softmax(torch.rand(initial_batch_size, n_classes, device=device), dim=1)

    # Sort input_pdf based on argmax values to evenly distribute and order classes
    set_labels_large = torch.argmax(input_pdf_large, dim=1)
    sorted_indices = torch.argsort(set_labels_large)
    ordered_input_pdf = input_pdf_large[sorted_indices]

    # Ensure we pick exactly 'samples_per_class' for each class
    input_pdf = torch.zeros((batch_size, n_classes), device=device)
    for i in range(n_classes):
        indices = (set_labels_large == i).nonzero(as_tuple=True)[0][:samples_per_class]
        input_pdf[i * samples_per_class:(i + 1) * samples_per_class] = input_pdf_large[indices]

    return noise, input_pdf

# Example usage:
batch_size = 100  # 10 classes * 10 samples each
n_classes = 10
nz = 144  # Example size for the noise dimension
noise, input_pdf = generate_sorted_input_pdf(batch_size, n_classes, nz)

print("Noise Shape:", noise.shape)
print("Input PDF Shape:", input_pdf)
print("Input PDF Shape:", input_pdf.shape)
print("Set Labels (Sorted):", torch.argmax(input_pdf, dim=1))

def generate_ordered_one_hot_noise(batch_size, n_classes, nz, samples_per_class=10, device=None):
    # Generate noise
    noise = torch.randn(batch_size, nz, 1, 1, device=device)

    # Generate one-hot labels in order from 0 to n_classes-1
    labels = torch.arange(n_classes).repeat_interleave(samples_per_class).to(device)
    one_hot_labels = torch.nn.functional.one_hot(labels, num_classes=n_classes).float()

    return noise, one_hot_labels

def weights_initialization_gen_xavier(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.xavier_normal_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

def weights_initialization_gen_ortho(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.orthogonal_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

def weights_initialization_gen_normal(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.normal_(m.weight, mean=0.0, std=0.02)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

def weights_initialization_gen_uniform(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.uniform_(m.weight, -0.08, 0.08)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

def cosine_similarity_loss(features):
    normalized_features = F.normalize(features, p=2, dim=1)
    similarity_matrix = torch.mm(normalized_features, normalized_features.t())
    mask = torch.eye(similarity_matrix.size(0), device=similarity_matrix.device).bool()
    similarity_matrix = similarity_matrix.masked_fill(mask, 0)
    loss = similarity_matrix.sum() / (features.size(0) * (features.size(0) - 1))
    return loss  # Minimize

def feature_orthogonality_loss(features):
    gram_matrix = torch.mm(features, features.t())
    identity_matrix = torch.eye(gram_matrix.size(0), device=gram_matrix.device)
    loss = torch.mean((gram_matrix - identity_matrix) ** 2)
    return loss / (features.size(0) * features.size(1))  # Minimize

def kl_divergence(p, q):

    p = F.softmax(p, dim=1)
    q = F.softmax(q, dim=1)

    kl_div = F.kl_div(p.log(), q, reduction='batchmean')

    return kl_div

def add_l1_perturbation(images, perturbation_bound):
    # Generate random perturbation
    perturbation = torch.randn_like(images)

    # Normalize the perturbation to have an L1 norm of 1
    perturbation = perturbation / perturbation.abs().sum(dim=[1, 2, 3], keepdim=True)

    # Scale perturbation by the L1 bound
    perturbation = perturbation * perturbation_bound

    # Add the perturbation to the images
    perturbed_images = images + perturbation

    return perturbed_images

def add_l2_perturbation(images, perturbation_bound):
    # Generate random perturbation
    perturbation = torch.randn_like(images)

    # Normalize the perturbation to have an L2 norm of 1
    perturbation = perturbation / perturbation.view(perturbation.size(0), -1).norm(p=2, dim=1).view(-1, 1, 1, 1)

    # Scale perturbation by the L2 bound
    perturbation = perturbation * perturbation_bound

    # Add the perturbation to the images
    perturbed_images = images + perturbation

    return perturbed_images

def add_linf_perturbation(images, perturbation_bound):
    # Generate random perturbation
    perturbation = torch.randn_like(images)

    # Scale the perturbation so that its maximum absolute value does not exceed the perturbation bound
    perturbation = perturbation_bound * torch.sign(perturbation)

    # Add the perturbation to the images
    perturbed_images = images + perturbation

    return perturbed_images

def total_variation_loss(generated_images):
    """
    Computes the Total Variation Loss for a batch of generated images.

    Parameters:
    generated_images (torch.Tensor): A batch of generated images of shape (batch_size, channels, height, width).

    Returns:
    torch.Tensor: The total variation loss.
    """
    batch_size = generated_images.size(0)
    h_variation = torch.pow(generated_images[:, :, 1:, :] - generated_images[:, :, :-1, :], 2).sum()
    w_variation = torch.pow(generated_images[:, :, :, 1:] - generated_images[:, :, :, :-1], 2).sum()

    return (h_variation + w_variation) / batch_size

import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

def save_tsne_plot(features, labels, epoch, save_dir='MNIST-Inversion/fin9/tsne'):
    # Ensure the save directory exists
    os.makedirs(save_dir, exist_ok=True)

    # Convert the features and labels to numpy arrays
    features_np = np.array(features)
    labels_np = np.array(labels)
    # Apply t-SNE to reduce dimensionality to 2D
    tsne = TSNE(n_components=2, random_state=42)
    tsne_results = tsne.fit_transform(features_np)

    # Create a scatter plot
    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=labels_np, cmap='tab10', alpha=0.6)
    plt.colorbar(scatter)
    plt.title(f"t-SNE Plot at Epoch {epoch + 1}")
    plt.xlabel("t-SNE Dimension 1")
    plt.ylabel("t-SNE Dimension 2")

    # Save the plot
    save_path = os.path.join(save_dir, f"tsne_epoch_{epoch + 1}.png")
    plt.savefig(save_path)
    plt.close()

    print(f"t-SNE plot saved at: {save_path}")

from sklearn.decomposition import PCA

def save_pca_plot(features, labels, epoch, save_dir='MNIST-Inversion/fin9/pca'):
    # Ensure the save directory exists
    os.makedirs(save_dir, exist_ok=True)

    # Convert the features and labels to numpy arrays
    features_np = np.array(features)
    labels_np = np.array(labels)

    # Apply PCA to reduce dimensionality to 2D
    pca = PCA(n_components=2)
    pca_results = pca.fit_transform(features_np)

    # Create a scatter plot
    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(pca_results[:, 0], pca_results[:, 1], c=labels_np, cmap='tab10', alpha=0.6)
    plt.colorbar(scatter)
    plt.title(f"PCA Plot at Epoch {epoch + 1}")
    plt.xlabel("PCA Component 1")
    plt.ylabel("PCA Component 2")

    # Save the plot
    save_path = os.path.join(save_dir, f"pca_epoch_{epoch + 1}.png")
    plt.savefig(save_path)
    plt.close()

    print(f"PCA plot saved at: {save_path}")

class Generator(nn.Module):
    def __init__(self, nz, ngf, nc, n_classes):
        super(Generator, self).__init__()
        # Linear layer to map the softmaxed vector to the size nz
        self.embed = nn.Linear(n_classes, nz)

        # The main model architecture
        self.main = nn.Sequential(
            # Input is (nz * 2) x 1 x 1
            nn.ConvTranspose2d(nz * 2, ngf * 4, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.Dropout2d(0.2),
            nn.Dropout2d(0.3),
            nn.ReLU(True),
            # State size: (ngf * 4) x 4 x 4

            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.Dropout2d(0.2),
            nn.Dropout2d(0.3),
            nn.ReLU(True),
            # State size: (ngf * 2) x 8 x 8

            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.Dropout2d(0.2),
            nn.Dropout2d(0.3),
            nn.ReLU(True),
            # State size: (ngf) x 16 x 16

            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # State size: (nc) x 32 x 32
        )

    def forward(self, z, class_vector):
        # Map the class vector to the latent space size
        embed_vector = self.embed(class_vector).unsqueeze(-1).unsqueeze(-1)
        # print(f"Embedding Vector Shape: {embed_vector.shape}")

        # Concatenate with the latent vector z
        input = torch.cat([z, embed_vector], 1)
        # print(f"Input Shape after concatenation: {input.shape}")

        # Pass through the main model
        out = self.main(input)
        return out



"""Inversion

**ALL 5 LOSSES COME INTO PLAY **
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from PIL import Image
import IPython.display as display


# Assuming Classifier and Generator are defined elsewhere
# and relevant functions are defined (e.g., kl_divergence, cosine_similarity_loss, etc.)
nc = 3
ncf = 64
# Model and optimizer setup
csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('SVHN/svhn_csf_10.pth' , weights_only = True))
ngf = 32
gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.003, weight_decay=1e-4)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.01)

n_classes = 10
batch_size = 2048
labels_per_class = 10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 1e-4

# Create output directory if it does not exist
output_dir = 'SVHN/new1/'
os.makedirs(output_dir, exist_ok=True)
num_epochs = 4000

# Lists to store metrics
kl_divergence_values = []
cross_entropy_values = []
orthogonality_losses = []
cosine_similarities = []
accuracies = []

import os
import torch
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from PIL import Image

# Function to label and save images in grid format
def save_labeled_images(images, epoch, output_dir):
    fig, axs = plt.subplots(1, 1, figsize=(10, 10))

    # Move images to CPU and create a grid of images
    images = images.cpu()
    grid_image = vutils.make_grid(images, nrow=10, normalize=True)
    grid_image = grid_image.permute(1, 2, 0)  # Convert from CHW to HWC

    # Display image
    axs.imshow(grid_image)
    axs.axis('off')

    # Save the image without adding a title
    fig.savefig(f"{output_dir}/labeled_image_{epoch + 1}.png", bbox_inches='tight')
    plt.close(fig)

# To combine all saved images into a matrix with 3 columns and labels on top (outside images)
def combine_images(output_dir, epoch_list, columns=3):
    rows = len(epoch_list) // columns + (len(epoch_list) % columns > 0)
    fig, axs = plt.subplots(rows, columns, figsize=(columns * 5, rows * 6))

    # Loop through each epoch image and plot it in the grid with labels outside the image
    for idx, epoch in enumerate(epoch_list):
        img_path = f"{output_dir}/labeled_image_{epoch}.png"
        img = Image.open(img_path)

        row_idx = idx // columns
        col_idx = idx % columns

        axs[row_idx, col_idx].imshow(img)
        axs[row_idx, col_idx].axis('off')

        # Set the label on top of the image (outside the image)
        axs[row_idx, col_idx].set_title(f"Epoch {epoch}", fontsize=12, pad=10)

    # Remove any unused axes
    for idx in range(len(epoch_list), rows * columns):
        fig.delaxes(axs.flatten()[idx])

    # Save the combined grid of images
    plt.tight_layout()
    plt.savefig(f"{output_dir}/combined_images_with_labels.png", bbox_inches='tight')
    plt.show()

# Training loop with saving images and combining them at the end
best_accuracy = 0.0
best_epoch = 0

# Specify the epochs to plot: 1st, 500th, 1000th, 2000th, 3000th, 4000th
epoch_list = [1, 500, 1000, 2000, 3000, 4000]
for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    # Generate random noise and input PDFs
    noise = torch.randn(batch_size, nz, 1, 1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    # Generate images
    gen_images = gen(noise, input_pdf)

    # Register hooks (assumed functions `hook_function0` and `hook_function1` defined elsewhere)
    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    # Evaluate with the classifier
    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    # Calculate losses (assumed loss functions defined elsewhere)
    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarity = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()
    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    # Total loss calculation
    loss = (
        8000 * cosine_similarity  # Reduced cosine similarity weight
        + 100 * orthogonality_loss
        + 500 * cross_entropy
        + 20 * kl_divergence_value
        + lambda_l1 * l1_regularization
    )

    # Backpropagation and optimization step
    loss.backward()
    gen_optimizer.step()

    # Clean up hooks and features
    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    # Store metrics
    kl_divergence_values.append(kl_divergence_value.item())
    cross_entropy_values.append(cross_entropy.item())
    orthogonality_losses.append(orthogonality_loss.item())
    cosine_similarities.append(cosine_similarity.item())
    accuracies.append(accuracy.item())

    # Update best accuracy and epoch if this is the highest accuracy so far
    if accuracy.item() > best_accuracy:
        best_accuracy = accuracy.item()
        best_epoch = epoch + 1  # 1-based epoch number

    # Logging the losses and accuracy
    print(f"Epoch {epoch + 1}/{num_epochs}, KLD: {kl_divergence_value.item():.4f}, "
          f"CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, "
          f"CS: {cosine_similarity.item():.4f}, IA: {accuracy.item():.4f}")

    # Save and display generated images at specific epochs
    if (epoch + 1) in epoch_list:
        with torch.no_grad():
            fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
            save_labeled_images(fixed_gen_images, epoch, output_dir)  # Label and save the image

# Combine all labeled images in a matrix with 3 columns and labels on top (outside the images)
combine_images(output_dir, epoch_list, columns=3)

# Plotting IA (Accuracy) over epochs and marking the maximum IA
plt.figure(figsize=(10, 6))
plt.plot(range(1, num_epochs + 1), accuracies, label='IA (Accuracy)', color='blue')
plt.scatter(best_epoch, best_accuracy, color='red', zorder=5)
plt.text(best_epoch, best_accuracy, f"Max IA: {best_accuracy:.4f} at epoch {best_epoch}",
         horizontalalignment='right', color='red', fontsize=12)

plt.xlabel('Epochs')
plt.ylabel('IA (Accuracy)')
plt.title('IA (Accuracy) over Epochs with Maximum IA Highlighted')
plt.legend()
plt.grid(True)
plt.show()

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from PIL import Image
import IPython.display as display


# Assuming Classifier and Generator are defined elsewhere
# and relevant functions are defined (e.g., kl_divergence, cosine_similarity_loss, etc.)
nc = 3
ncf = 64
# Model and optimizer setup
csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('SVHN/svhn_csf_10.pth' , weights_only = True))
ngf = 32
gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.003, weight_decay=1e-4)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.001)

n_classes = 10
batch_size = 2048
labels_per_class = 10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 1e-4

# Create output directory if it does not exist
output_dir = 'SVHN/new1/'
os.makedirs(output_dir, exist_ok=True)
num_epochs = 4000

# Lists to store metrics
kl_divergence_values = []
cross_entropy_values = []
orthogonality_losses = []
cosine_similarities = []
accuracies = []

import os
import torch
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from PIL import Image

# Function to label and save images in grid format
def save_labeled_images(images, epoch, output_dir):
    fig, axs = plt.subplots(1, 1, figsize=(10, 10))

    # Move images to CPU and create a grid of images
    images = images.cpu()
    grid_image = vutils.make_grid(images, nrow=10, normalize=True)
    grid_image = grid_image.permute(1, 2, 0)  # Convert from CHW to HWC

    # Display image
    axs.imshow(grid_image)
    axs.axis('off')

    # Save the image without adding a title
    fig.savefig(f"{output_dir}/labeled_image_{epoch + 1}.png", bbox_inches='tight')
    plt.close(fig)

# To combine all saved images into a matrix with 3 columns and labels on top (outside images)
def combine_images(output_dir, epoch_list, columns=3):
    rows = len(epoch_list) // columns + (len(epoch_list) % columns > 0)
    fig, axs = plt.subplots(rows, columns, figsize=(columns * 5, rows * 6))

    # Loop through each epoch image and plot it in the grid with labels outside the image
    for idx, epoch in enumerate(epoch_list):
        img_path = f"{output_dir}/labeled_image_{epoch}.png"
        img = Image.open(img_path)

        row_idx = idx // columns
        col_idx = idx % columns

        axs[row_idx, col_idx].imshow(img)
        axs[row_idx, col_idx].axis('off')

        # Set the label on top of the image (outside the image)
        axs[row_idx, col_idx].set_title(f"Epoch {epoch}", fontsize=12, pad=10)

    # Remove any unused axes
    for idx in range(len(epoch_list), rows * columns):
        fig.delaxes(axs.flatten()[idx])

    # Save the combined grid of images
    plt.tight_layout()
    plt.savefig(f"{output_dir}/combined_images_with_labels.png", bbox_inches='tight')
    plt.show()

# Training loop with saving images and combining them at the end
best_accuracy = 0.0
best_epoch = 0

# Specify the epochs to plot: 1st, 500th, 1000th, 2000th, 3000th, 4000th
epoch_list = [1, 500, 1000, 2000, 3000, 4000]
for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    # Generate random noise and input PDFs
    noise = torch.randn(batch_size, nz, 1, 1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    # Generate images
    gen_images = gen(noise, input_pdf)

    # Register hooks (assumed functions `hook_function0` and `hook_function1` defined elsewhere)
    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    # Evaluate with the classifier
    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    # Calculate losses (assumed loss functions defined elsewhere)
    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarity = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()
    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    # Total loss calculation
    loss = (
        8000 * cosine_similarity  # Reduced cosine similarity weight
        + 100 * orthogonality_loss
        + 500 * cross_entropy
        + 20 * kl_divergence_value
        + lambda_l1 * l1_regularization
    )

    # Backpropagation and optimization step
    loss.backward()
    gen_optimizer.step()

    # Clean up hooks and features
    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    # Store metrics
    kl_divergence_values.append(kl_divergence_value.item())
    cross_entropy_values.append(cross_entropy.item())
    orthogonality_losses.append(orthogonality_loss.item())
    cosine_similarities.append(cosine_similarity.item())
    accuracies.append(accuracy.item())

    # Update best accuracy and epoch if this is the highest accuracy so far
    if accuracy.item() > best_accuracy:
        best_accuracy = accuracy.item()
        best_epoch = epoch + 1  # 1-based epoch number

    # Logging the losses and accuracy
    print(f"Epoch {epoch + 1}/{num_epochs}, KLD: {kl_divergence_value.item():.4f}, "
          f"CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, "
          f"CS: {cosine_similarity.item():.4f}, IA: {accuracy.item():.4f}")

    # Save and display generated images at specific epochs
    if (epoch + 1) in epoch_list:
        with torch.no_grad():
            fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
            save_labeled_images(fixed_gen_images, epoch, output_dir)  # Label and save the image

# Combine all labeled images in a matrix with 3 columns and labels on top (outside the images)
combine_images(output_dir, epoch_list, columns=3)

# Plotting IA (Accuracy) over epochs and marking the maximum IA
plt.figure(figsize=(10, 6))
plt.plot(range(1, num_epochs + 1), accuracies, label='IA (Accuracy)', color='blue')
plt.scatter(best_epoch, best_accuracy, color='red', zorder=5)
plt.text(best_epoch, best_accuracy, f"Max IA: {best_accuracy:.4f} at epoch {best_epoch}",
         horizontalalignment='right', color='red', fontsize=12)

plt.xlabel('Epochs')
plt.ylabel('IA (Accuracy)')
plt.title('IA (Accuracy) over Epochs with Maximum IA Highlighted')
plt.legend()
plt.grid(True)
plt.show()

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from PIL import Image
import IPython.display as display


# Assuming Classifier and Generator are defined elsewhere
# and relevant functions are defined (e.g., kl_divergence, cosine_similarity_loss, etc.)
nc = 3
ncf = 64
# Model and optimizer setup
csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('SVHN/svhn_csf_10.pth' , weights_only = True))
ngf = 32
gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.003, weight_decay=1e-4)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.001)

n_classes = 10
batch_size = 2048
labels_per_class = 10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 1e-4

# Create output directory if it does not exist
output_dir = 'SVHN/new2/'
os.makedirs(output_dir, exist_ok=True)
num_epochs = 4000

# Lists to store metrics
kl_divergence_values = []
cross_entropy_values = []
orthogonality_losses = []
cosine_similarities = []
accuracies = []

import os
import torch
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from PIL import Image

# Function to label and save images in grid format
def save_labeled_images(images, epoch, output_dir):
    fig, axs = plt.subplots(1, 1, figsize=(10, 10))

    # Move images to CPU and create a grid of images
    images = images.cpu()
    grid_image = vutils.make_grid(images, nrow=10, normalize=True)
    grid_image = grid_image.permute(1, 2, 0)  # Convert from CHW to HWC

    # Display image
    axs.imshow(grid_image)
    axs.axis('off')

    # Save the image without adding a title
    fig.savefig(f"{output_dir}/labeled_image_{epoch + 1}.png", bbox_inches='tight')
    plt.close(fig)

# To combine all saved images into a matrix with 3 columns and labels on top (outside images)
def combine_images(output_dir, epoch_list, columns=3):
    rows = len(epoch_list) // columns + (len(epoch_list) % columns > 0)
    fig, axs = plt.subplots(rows, columns, figsize=(columns * 5, rows * 6))

    # Loop through each epoch image and plot it in the grid with labels outside the image
    for idx, epoch in enumerate(epoch_list):
        img_path = f"{output_dir}/labeled_image_{epoch}.png"
        img = Image.open(img_path)

        row_idx = idx // columns
        col_idx = idx % columns

        axs[row_idx, col_idx].imshow(img)
        axs[row_idx, col_idx].axis('off')

        # Set the label on top of the image (outside the image)
        axs[row_idx, col_idx].set_title(f"Epoch {epoch}", fontsize=12, pad=10)

    # Remove any unused axes
    for idx in range(len(epoch_list), rows * columns):
        fig.delaxes(axs.flatten()[idx])

    # Save the combined grid of images
    plt.tight_layout()
    plt.savefig(f"{output_dir}/combined_images_with_labels.png", bbox_inches='tight')
    plt.show()

# Training loop with saving images and combining them at the end
best_accuracy = 0.0
best_epoch = 0

# Specify the epochs to plot: 1st, 500th, 1000th, 2000th, 3000th, 4000th
epoch_list = [1, 500, 1000, 2000, 3000, 4000]
for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    # Generate random noise and input PDFs
    noise = torch.randn(batch_size, nz, 1, 1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    # Generate images
    gen_images = gen(noise, input_pdf)

    # Register hooks (assumed functions `hook_function0` and `hook_function1` defined elsewhere)
    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    # Evaluate with the classifier
    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    # Calculate losses (assumed loss functions defined elsewhere)
    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarity = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()
    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    # Total loss calculation
    loss = (
        10000 * cosine_similarity  # Reduced cosine similarity weight
        #+ 100 * orthogonality_loss
        + 500 * cross_entropy
        #+ 20 * kl_divergence_value
        #+ lambda_l1 * l1_regularization
    )

    # Backpropagation and optimization step
    loss.backward()
    gen_optimizer.step()

    # Clean up hooks and features
    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    # Store metrics
    kl_divergence_values.append(kl_divergence_value.item())
    cross_entropy_values.append(cross_entropy.item())
    orthogonality_losses.append(orthogonality_loss.item())
    cosine_similarities.append(cosine_similarity.item())
    accuracies.append(accuracy.item())

    # Update best accuracy and epoch if this is the highest accuracy so far
    if accuracy.item() > best_accuracy:
        best_accuracy = accuracy.item()
        best_epoch = epoch + 1  # 1-based epoch number

    # Logging the losses and accuracy
    print(f"Epoch {epoch + 1}/{num_epochs}, KLD: {kl_divergence_value.item():.4f}, "
          f"CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, "
          f"CS: {cosine_similarity.item():.4f}, IA: {accuracy.item():.4f}")

    # Save and display generated images at specific epochs
    if (epoch + 1) in epoch_list:
        with torch.no_grad():
            fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
            save_labeled_images(fixed_gen_images, epoch, output_dir)  # Label and save the image

# Combine all labeled images in a matrix with 3 columns and labels on top (outside the images)
combine_images(output_dir, epoch_list, columns=3)

# Plotting IA (Accuracy) over epochs and marking the maximum IA
plt.figure(figsize=(10, 6))
plt.plot(range(1, num_epochs + 1), accuracies, label='IA (Accuracy)', color='blue')
plt.scatter(best_epoch, best_accuracy, color='red', zorder=5)
plt.text(best_epoch, best_accuracy, f"Max IA: {best_accuracy:.4f} at epoch {best_epoch}",
         horizontalalignment='right', color='red', fontsize=12)

plt.xlabel('Epochs')
plt.ylabel('IA (Accuracy)')
plt.title('IA (Accuracy) over Epochs with Maximum IA Highlighted')
plt.legend()
plt.grid(True)
plt.show()

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from PIL import Image
import IPython.display as display


# Assuming Classifier and Generator are defined elsewhere
# and relevant functions are defined (e.g., kl_divergence, cosine_similarity_loss, etc.)
nc = 3
ncf = 64
# Model and optimizer setup
csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('SVHN/svhn_csf_10.pth' , weights_only = True))
ngf = 32
gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.001, weight_decay=1e-4)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0)

n_classes = 10
batch_size = 2048
labels_per_class = 10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 1e-4

# Create output directory if it does not exist
output_dir = 'SVHN/new3/'
os.makedirs(output_dir, exist_ok=True)
num_epochs = 4000

# Lists to store metrics
kl_divergence_values = []
cross_entropy_values = []
orthogonality_losses = []
cosine_similarities = []
accuracies = []

import os
import torch
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from PIL import Image

# Function to label and save images in grid format
def save_labeled_images(images, epoch, output_dir):
    fig, axs = plt.subplots(1, 1, figsize=(10, 10))

    # Move images to CPU and create a grid of images
    images = images.cpu()
    grid_image = vutils.make_grid(images, nrow=10, normalize=True)
    grid_image = grid_image.permute(1, 2, 0)  # Convert from CHW to HWC

    # Display image
    axs.imshow(grid_image)
    axs.axis('off')

    # Save the image without adding a title
    fig.savefig(f"{output_dir}/labeled_image_{epoch + 1}.png", bbox_inches='tight')
    plt.close(fig)

# To combine all saved images into a matrix with 3 columns and labels on top (outside images)
def combine_images(output_dir, epoch_list, columns=3):
    rows = len(epoch_list) // columns + (len(epoch_list) % columns > 0)
    fig, axs = plt.subplots(rows, columns, figsize=(columns * 5, rows * 6))

    # Loop through each epoch image and plot it in the grid with labels outside the image
    for idx, epoch in enumerate(epoch_list):
        img_path = f"{output_dir}/labeled_image_{epoch}.png"
        img = Image.open(img_path)

        row_idx = idx // columns
        col_idx = idx % columns

        axs[row_idx, col_idx].imshow(img)
        axs[row_idx, col_idx].axis('off')

        # Set the label on top of the image (outside the image)
        axs[row_idx, col_idx].set_title(f"Epoch {epoch}", fontsize=12, pad=10)

    # Remove any unused axes
    for idx in range(len(epoch_list), rows * columns):
        fig.delaxes(axs.flatten()[idx])

    # Save the combined grid of images
    plt.tight_layout()
    plt.savefig(f"{output_dir}/combined_images_with_labels.png", bbox_inches='tight')
    plt.show()

# Training loop with saving images and combining them at the end
best_accuracy = 0.0
best_epoch = 0

# Specify the epochs to plot: 1st, 500th, 1000th, 2000th, 3000th, 4000th
epoch_list = [1, 500, 1000, 2000, 3000, 4000]
for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    # Generate random noise and input PDFs
    noise = torch.randn(batch_size, nz, 1, 1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    # Generate images
    gen_images = gen(noise, input_pdf)

    # Register hooks (assumed functions `hook_function0` and `hook_function1` defined elsewhere)
    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    # Evaluate with the classifier
    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    # Calculate losses (assumed loss functions defined elsewhere)
    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarity = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()
    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    # Total loss calculation
    loss = (
        10000 * cosine_similarity  # Reduced cosine similarity weight
        #+ 100 * orthogonality_loss
        + 500 * cross_entropy
        #+ 20 * kl_divergence_value
        #+ lambda_l1 * l1_regularization
    )

    # Backpropagation and optimization step
    loss.backward()
    gen_optimizer.step()

    # Clean up hooks and features
    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    # Store metrics
    kl_divergence_values.append(kl_divergence_value.item())
    cross_entropy_values.append(cross_entropy.item())
    orthogonality_losses.append(orthogonality_loss.item())
    cosine_similarities.append(cosine_similarity.item())
    accuracies.append(accuracy.item())

    # Update best accuracy and epoch if this is the highest accuracy so far
    if accuracy.item() > best_accuracy:
        best_accuracy = accuracy.item()
        best_epoch = epoch + 1  # 1-based epoch number

    # Logging the losses and accuracy
    print(f"Epoch {epoch + 1}/{num_epochs}, KLD: {kl_divergence_value.item():.4f}, "
          f"CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, "
          f"CS: {cosine_similarity.item():.4f}, IA: {accuracy.item():.4f}")

    # Save and display generated images at specific epochs
    if (epoch + 1) in epoch_list:
        with torch.no_grad():
            fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
            save_labeled_images(fixed_gen_images, epoch, output_dir)  # Label and save the image

# Combine all labeled images in a matrix with 3 columns and labels on top (outside the images)
combine_images(output_dir, epoch_list, columns=3)

# Plotting IA (Accuracy) over epochs and marking the maximum IA
plt.figure(figsize=(10, 6))
plt.plot(range(1, num_epochs + 1), accuracies, label='IA (Accuracy)', color='blue')
plt.scatter(best_epoch, best_accuracy, color='red', zorder=5)
plt.text(best_epoch, best_accuracy, f"Max IA: {best_accuracy:.4f} at epoch {best_epoch}",
         horizontalalignment='right', color='red', fontsize=12)

plt.xlabel('Epochs')
plt.ylabel('IA (Accuracy)')
plt.title('IA (Accuracy) over Epochs with Maximum IA Highlighted')
plt.legend()
plt.grid(True)
plt.show()

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from PIL import Image
import IPython.display as display


# Assuming Classifier and Generator are defined elsewhere
# and relevant functions are defined (e.g., kl_divergence, cosine_similarity_loss, etc.)
nc = 3
ncf = 64
# Model and optimizer setup
csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('SVHN/svhn_csf_10.pth' , weights_only = True))
ngf = 32
gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.003, weight_decay=1e-4)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.01)

n_classes = 10
batch_size = 2048
labels_per_class = 10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 1e-4

# Create output directory if it does not exist
output_dir = 'SVHN/new4/'
os.makedirs(output_dir, exist_ok=True)
num_epochs = 4000

# Lists to store metrics
kl_divergence_values = []
cross_entropy_values = []
orthogonality_losses = []
cosine_similarities = []
accuracies = []

import os
import torch
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from PIL import Image

# Function to label and save images in grid format
def save_labeled_images(images, epoch, output_dir):
    fig, axs = plt.subplots(1, 1, figsize=(10, 10))

    # Move images to CPU and create a grid of images
    images = images.cpu()
    grid_image = vutils.make_grid(images, nrow=10, normalize=True)
    grid_image = grid_image.permute(1, 2, 0)  # Convert from CHW to HWC

    # Display image
    axs.imshow(grid_image)
    axs.axis('off')

    # Save the image without adding a title
    fig.savefig(f"{output_dir}/labeled_image_{epoch + 1}.png", bbox_inches='tight')
    plt.close(fig)

# To combine all saved images into a matrix with 3 columns and labels on top (outside images)
def combine_images(output_dir, epoch_list, columns=3):
    rows = len(epoch_list) // columns + (len(epoch_list) % columns > 0)
    fig, axs = plt.subplots(rows, columns, figsize=(columns * 5, rows * 6))

    # Loop through each epoch image and plot it in the grid with labels outside the image
    for idx, epoch in enumerate(epoch_list):
        img_path = f"{output_dir}/labeled_image_{epoch}.png"
        img = Image.open(img_path)

        row_idx = idx // columns
        col_idx = idx % columns

        axs[row_idx, col_idx].imshow(img)
        axs[row_idx, col_idx].axis('off')

        # Set the label on top of the image (outside the image)
        axs[row_idx, col_idx].set_title(f"Epoch {epoch}", fontsize=12, pad=10)

    # Remove any unused axes
    for idx in range(len(epoch_list), rows * columns):
        fig.delaxes(axs.flatten()[idx])

    # Save the combined grid of images
    plt.tight_layout()
    plt.savefig(f"{output_dir}/combined_images_with_labels.png", bbox_inches='tight')
    plt.show()

# Training loop with saving images and combining them at the end
best_accuracy = 0.0
best_epoch = 0

# Specify the epochs to plot: 1st, 500th, 1000th, 2000th, 3000th, 4000th
epoch_list = [1, 500, 1000, 2000, 3000, 4000]
for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    # Generate random noise and input PDFs
    noise = torch.randn(batch_size, nz, 1, 1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    # Generate images
    gen_images = gen(noise, input_pdf)

    # Register hooks (assumed functions `hook_function0` and `hook_function1` defined elsewhere)
    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    # Evaluate with the classifier
    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    # Calculate losses (assumed loss functions defined elsewhere)
    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarity = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()
    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    # Total loss calculation
    loss = (
        100 * cosine_similarity  # Reduced cosine similarity weight
        #+ 100 * orthogonality_loss
        + 5 * cross_entropy
        #+ 20 * kl_divergence_value
        #+ lambda_l1 * l1_regularization
    )

    # Backpropagation and optimization step
    loss.backward()
    gen_optimizer.step()

    # Clean up hooks and features
    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    # Store metrics
    kl_divergence_values.append(kl_divergence_value.item())
    cross_entropy_values.append(cross_entropy.item())
    orthogonality_losses.append(orthogonality_loss.item())
    cosine_similarities.append(cosine_similarity.item())
    accuracies.append(accuracy.item())

    # Update best accuracy and epoch if this is the highest accuracy so far
    if accuracy.item() > best_accuracy:
        best_accuracy = accuracy.item()
        best_epoch = epoch + 1  # 1-based epoch number

    # Logging the losses and accuracy
    print(f"Epoch {epoch + 1}/{num_epochs}, KLD: {kl_divergence_value.item():.4f}, "
          f"CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, "
          f"CS: {cosine_similarity.item():.4f}, IA: {accuracy.item():.4f}")

    # Save and display generated images at specific epochs
    if (epoch + 1) in epoch_list:
        with torch.no_grad():
            fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
            save_labeled_images(fixed_gen_images, epoch, output_dir)  # Label and save the image

# Combine all labeled images in a matrix with 3 columns and labels on top (outside the images)
combine_images(output_dir, epoch_list, columns=3)

# Plotting IA (Accuracy) over epochs and marking the maximum IA
plt.figure(figsize=(10, 6))
plt.plot(range(1, num_epochs + 1), accuracies, label='IA (Accuracy)', color='blue')
plt.scatter(best_epoch, best_accuracy, color='red', zorder=5)
plt.text(best_epoch, best_accuracy, f"Max IA: {best_accuracy:.4f} at epoch {best_epoch}",
         horizontalalignment='right', color='red', fontsize=12)

plt.xlabel('Epochs')
plt.ylabel('IA (Accuracy)')
plt.title('IA (Accuracy) over Epochs with Maximum IA Highlighted')
plt.legend()
plt.grid(True)
plt.show()

# Plotting the losses after training
plt.figure(figsize=(14, 10))

# Plot KL Divergence over epochs
plt.subplot(2, 2, 1)
plt.plot(kl_divergence_values, label='KL Divergence', color='green')
plt.xlabel('Epoch')
plt.ylabel('KL Divergence')
plt.title('KL Divergence over Epochs')
plt.legend()

# Plot Cross Entropy loss over epochs
plt.subplot(2, 2, 2)
plt.plot(cross_entropy_values, label='Cross Entropy', color='orange')
plt.xlabel('Epoch')
plt.ylabel('Cross Entropy')
plt.title('Cross Entropy Loss over Epochs')
plt.legend()

# Plot Orthogonality loss over epochs
plt.subplot(2, 2, 3)
plt.plot(orthogonality_losses, label='Orthogonality Loss', color='purple')
plt.xlabel('Epoch')
plt.ylabel('Orthogonality Loss')
plt.title('Orthogonality Loss over Epochs')
plt.legend()

# Plot Cosine Similarity over epochs
plt.subplot(2, 2, 4)
plt.plot(cosine_similarities, label='Cosine Similarity', color='red')
plt.xlabel('Epoch')
plt.ylabel('Cosine Similarity')
plt.title('Cosine Similarity over Epochs')
plt.legend()

# Adjust the layout
plt.tight_layout()
plt.show()

plt.plot(accuracies, label='Accuracy vs Epoch', color='green')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Accuracy over Epochs')
plt.legend()

"""**COMMENTING OUT COSINE LOSS**"""



import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw, ImageFont
import IPython.display as display

# Assuming Classifier and Generator are defined elsewhere
# and relevant functions are defined (e.g., kl_divergence, cosine_similarity_loss, etc.)
nc = 3
ncf = 64
# Model and optimizer setup
csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('/content/data/cifar-10_best_7460.pth', weights_only=True))
ngf = 32
gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.001, weight_decay=1e-5)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.005)

n_classes = 10
batch_size = 256
labels_per_class = 10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 1e-6

# Create output directory if it does not exist
output_dir = 'MNIST-Inversion/new1/'
os.makedirs(output_dir, exist_ok=True)
num_epochs = 6000

# Lists to store metrics
kl_divergence_values = []
cross_entropy_values = []
orthogonality_losses = []
cosine_similarities = []
accuracies = []

# Function to add epoch label outside the image
def add_epoch_label_outside(image_tensor, epoch):
    # Clone the image tensor to CPU
    image = image_tensor.cpu().clone()
    image = vutils.make_grid(image, nrow=10, normalize=True)

    # Convert from CHW to HWC for plotting
    image = image.permute(1, 2, 0).numpy()

    # Convert to PIL image
    pil_image = Image.fromarray((image * 255).astype('uint8'))

    # Create a new image with extra space on top for the label
    new_height = pil_image.height + 30  # 30 pixels for the label
    new_image = Image.new('RGB', (pil_image.width, new_height), "black")

    # Paste the original image onto the new canvas
    new_image.paste(pil_image, (0, 30))  # 30 pixel offset

    # Add epoch label above the image
    draw = ImageDraw.Draw(new_image)
    font = ImageFont.load_default()  # Use default font
    draw.text((5, 5), f'Epoch: {epoch}', fill="white", font=font)

    return new_image

# Function to concatenate images in 3-column matrix format
def concatenate_images(images, n_cols=3):
    # Get individual image sizes
    widths, heights = zip(*(img.size for img in images))

    # Define the size of the grid
    max_width = max(widths)
    max_height = max(heights)
    n_rows = (len(images) + n_cols - 1) // n_cols

    # Create a blank image canvas
    concatenated_image = Image.new('RGB', (max_width * n_cols, max_height * n_rows))

    # Paste images into the canvas
    for i, img in enumerate(images):
        x_offset = (i % n_cols) * max_width
        y_offset = (i // n_cols) * max_height
        concatenated_image.paste(img, (x_offset, y_offset))

    return concatenated_image

# Training loop
saved_images = []
for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    # Generate random noise and input PDFs
    noise = torch.randn(batch_size, nz, 1, 1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    # Generate images
    gen_images = gen(noise, input_pdf)

    # Register hooks
    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    # Evaluate with the classifier
    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    # Calculate losses
    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarity = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()
    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    # Total loss calculation
    loss = (
        # 1500*cosine_similarity +
        + 70*orthogonality_loss
        + 45 * cross_entropy
        + 12* kl_divergence_value
        + lambda_l1 * l1_regularization
    )

    # Backpropagation and optimization step
    loss.backward()
    gen_optimizer.step()

    # Clean up hooks and features
    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    # Store metrics
    kl_divergence_values.append(kl_divergence_value.item())
    cross_entropy_values.append(cross_entropy.item())
    orthogonality_losses.append(orthogonality_loss.item())
    cosine_similarities.append(cosine_similarity.item())
    accuracies.append(accuracy.item())

    # Logging the losses and accuracy
    print(f"Epoch {epoch + 1}/{num_epochs}, KLD: {kl_divergence_value.item():.4f}, "
          f"CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, "
          f"CS: {cosine_similarity.item():.4f}, IA: {accuracy.item():.4f}")

    # Save and display generated images at specific epochs
    if (epoch + 1) in [1, 200, 500, 1000, 1200, 1500, 2000 , 4000 , 6000]:
        with torch.no_grad():
            fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
            image_with_label = add_epoch_label_outside(fixed_gen_images, epoch + 1)
            saved_images.append(image_with_label)

# Concatenate all saved images into a 3-column grid
if saved_images:
    concatenated_image = concatenate_images(saved_images, n_cols=3)
    concatenated_image.save(f"{output_dir}/concatenated_images_with_epochs.png")  # Save the concatenated image
    concatenated_image.show()  # Display the concatenated image

saved_images

"""**COMMENTING OUT ORTHOGONALITY LOSS**"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw, ImageFont
import IPython.display as display

# Assuming Classifier and Generator are defined elsewhere
# and relevant functions are defined (e.g., kl_divergence, cosine_similarity_loss, etc.)
nc = 3
ncf = 64
# Model and optimizer setup
csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('/content/data/cifar-10_best_7460.pth', weights_only=True))
ngf = 32
gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.001, weight_decay=1e-5)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.005)

n_classes = 10
batch_size = 256
labels_per_class = 10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 1e-6

# Create output directory if it does not exist
output_dir = 'MNIST-Inversion/new1/'
os.makedirs(output_dir, exist_ok=True)
num_epochs = 6000

# Lists to store metrics
kl_divergence_values = []
cross_entropy_values = []
orthogonality_losses = []
cosine_similarities = []
accuracies = []

# Function to add epoch label outside the image
def add_epoch_label_outside(image_tensor, epoch):
    # Clone the image tensor to CPU
    image = image_tensor.cpu().clone()
    image = vutils.make_grid(image, nrow=10, normalize=True)

    # Convert from CHW to HWC for plotting
    image = image.permute(1, 2, 0).numpy()

    # Convert to PIL image
    pil_image = Image.fromarray((image * 255).astype('uint8'))

    # Create a new image with extra space on top for the label
    new_height = pil_image.height + 30  # 30 pixels for the label
    new_image = Image.new('RGB', (pil_image.width, new_height), "black")

    # Paste the original image onto the new canvas
    new_image.paste(pil_image, (0, 30))  # 30 pixel offset

    # Add epoch label above the image
    draw = ImageDraw.Draw(new_image)
    font = ImageFont.load_default()  # Use default font
    draw.text((5, 5), f'Epoch: {epoch}', fill="white", font=font)

    return new_image

# Function to concatenate images in 3-column matrix format
def concatenate_images(images, n_cols=3):
    # Get individual image sizes
    widths, heights = zip(*(img.size for img in images))

    # Define the size of the grid
    max_width = max(widths)
    max_height = max(heights)
    n_rows = (len(images) + n_cols - 1) // n_cols

    # Create a blank image canvas
    concatenated_image = Image.new('RGB', (max_width * n_cols, max_height * n_rows))

    # Paste images into the canvas
    for i, img in enumerate(images):
        x_offset = (i % n_cols) * max_width
        y_offset = (i // n_cols) * max_height
        concatenated_image.paste(img, (x_offset, y_offset))

    return concatenated_image

# Training loop
saved_images = []
for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    # Generate random noise and input PDFs
    noise = torch.randn(batch_size, nz, 1, 1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    # Generate images
    gen_images = gen(noise, input_pdf)

    # Register hooks
    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    # Evaluate with the classifier
    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    # Calculate losses
    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarity = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()
    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    # Total loss calculation
    loss = (
        1500*cosine_similarity +
        #+ 70*orthogonality_loss
        + 45 * cross_entropy
        + 12* kl_divergence_value
        + lambda_l1 * l1_regularization
    )

    # Backpropagation and optimization step
    loss.backward()
    gen_optimizer.step()

    # Clean up hooks and features
    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    # Store metrics
    kl_divergence_values.append(kl_divergence_value.item())
    cross_entropy_values.append(cross_entropy.item())
    orthogonality_losses.append(orthogonality_loss.item())
    cosine_similarities.append(cosine_similarity.item())
    accuracies.append(accuracy.item())

    # Logging the losses and accuracy
    print(f"Epoch {epoch + 1}/{num_epochs}, KLD: {kl_divergence_value.item():.4f}, "
          f"CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, "
          f"CS: {cosine_similarity.item():.4f}, IA: {accuracy.item():.4f}")

    # Save and display generated images at specific epochs
    if (epoch + 1) in [1, 200, 500, 1000, 1200, 1500, 2000 , 4000 , 6000]:
        with torch.no_grad():
            fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
            image_with_label = add_epoch_label_outside(fixed_gen_images, epoch + 1)
            saved_images.append(image_with_label)

# Concatenate all saved images into a 3-column grid
if saved_images:
    concatenated_image = concatenate_images(saved_images, n_cols=3)
    concatenated_image.save(f"{output_dir}/concatenated_images_with_epochs.png")  # Save the concatenated image
    concatenated_image.show()  # Display the concatenated image

# Plotting the losses after training
plt.figure(figsize=(14, 10))

# Plot KL Divergence over epochs
plt.subplot(2, 2, 1)
plt.plot(kl_divergence_values, label='KL Divergence', color='green')
plt.xlabel('Epoch')
plt.ylabel('KL Divergence')
plt.title('KL Divergence over Epochs')
plt.legend()

# Plot Cross Entropy loss over epochs
plt.subplot(2, 2, 2)
plt.plot(cross_entropy_values, label='Cross Entropy', color='orange')
plt.xlabel('Epoch')
plt.ylabel('Cross Entropy')
plt.title('Cross Entropy Loss over Epochs')
plt.legend()

# Plot Orthogonality loss over epochs
plt.subplot(2, 2, 3)
plt.plot(orthogonality_losses, label='Orthogonality Loss', color='purple')
plt.xlabel('Epoch')
plt.ylabel('Orthogonality Loss')
plt.title('Orthogonality Loss over Epochs')
plt.legend()

# Plot Cosine Similarity over epochs
plt.subplot(2, 2, 4)
plt.plot(cosine_similarities, label='Cosine Similarity', color='red')
plt.xlabel('Epoch')
plt.ylabel('Cosine Similarity')
plt.title('Cosine Similarity over Epochs')
plt.legend()

# Adjust the layout
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))

# Plot accuracy over epochs
plt.plot(accuracies, label='Accuracy (IA)', color='blue')

# Highlight the maximum accuracy
max_accuracy = max(accuracies)
max_epoch = accuracies.index(max_accuracy)
plt.plot(max_epoch, max_accuracy, 'ro')  # mark max point
plt.text(max_epoch, max_accuracy, f'Max IA: {max_accuracy:.4f}', fontsize=10, color='red')

# Add labels and legend
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

"""**COMMENTING OUT CROSS ENTROPY LOSS**"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw, ImageFont
import IPython.display as display

# Assuming Classifier and Generator are defined elsewhere
# and relevant functions are defined (e.g., kl_divergence, cosine_similarity_loss, etc.)
nc = 3
ncf = 64
# Model and optimizer setup
csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('/content/data/cifar-10_best_7460.pth', weights_only=True))
ngf = 32
gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.001, weight_decay=1e-5)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.005)

n_classes = 10
batch_size = 256
labels_per_class = 10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 1e-6

# Create output directory if it does not exist
output_dir = 'MNIST-Inversion/new1/'
os.makedirs(output_dir, exist_ok=True)
num_epochs = 6000

# Lists to store metrics
kl_divergence_values = []
cross_entropy_values = []
orthogonality_losses = []
cosine_similarities = []
accuracies = []

# Function to add epoch label outside the image
def add_epoch_label_outside(image_tensor, epoch):
    # Clone the image tensor to CPU
    image = image_tensor.cpu().clone()
    image = vutils.make_grid(image, nrow=10, normalize=True)

    # Convert from CHW to HWC for plotting
    image = image.permute(1, 2, 0).numpy()

    # Convert to PIL image
    pil_image = Image.fromarray((image * 255).astype('uint8'))

    # Create a new image with extra space on top for the label
    new_height = pil_image.height + 30  # 30 pixels for the label
    new_image = Image.new('RGB', (pil_image.width, new_height), "black")

    # Paste the original image onto the new canvas
    new_image.paste(pil_image, (0, 30))  # 30 pixel offset

    # Add epoch label above the image
    draw = ImageDraw.Draw(new_image)
    font = ImageFont.load_default()  # Use default font
    draw.text((5, 5), f'Epoch: {epoch}', fill="white", font=font)

    return new_image

# Function to concatenate images in 3-column matrix format
def concatenate_images(images, n_cols=3):
    # Get individual image sizes
    widths, heights = zip(*(img.size for img in images))

    # Define the size of the grid
    max_width = max(widths)
    max_height = max(heights)
    n_rows = (len(images) + n_cols - 1) // n_cols

    # Create a blank image canvas
    concatenated_image = Image.new('RGB', (max_width * n_cols, max_height * n_rows))

    # Paste images into the canvas
    for i, img in enumerate(images):
        x_offset = (i % n_cols) * max_width
        y_offset = (i // n_cols) * max_height
        concatenated_image.paste(img, (x_offset, y_offset))

    return concatenated_image

# Training loop
saved_images = []
for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    # Generate random noise and input PDFs
    noise = torch.randn(batch_size, nz, 1, 1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    # Generate images
    gen_images = gen(noise, input_pdf)

    # Register hooks
    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    # Evaluate with the classifier
    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    # Calculate losses
    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarity = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()
    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    # Total loss calculation
    loss = (
        1500*cosine_similarity +
        + 70*orthogonality_loss
        + 45 * cross_entropy
        + 12* kl_divergence_value
        + lambda_l1 * l1_regularization
    )

    # Backpropagation and optimization step
    loss.backward()
    gen_optimizer.step()

    # Clean up hooks and features
    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    # Store metrics
    kl_divergence_values.append(kl_divergence_value.item())
    cross_entropy_values.append(cross_entropy.item())
    orthogonality_losses.append(orthogonality_loss.item())
    cosine_similarities.append(cosine_similarity.item())
    accuracies.append(accuracy.item())

    # Logging the losses and accuracy
    print(f"Epoch {epoch + 1}/{num_epochs}, KLD: {kl_divergence_value.item():.4f}, "
          f"CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, "
          f"CS: {cosine_similarity.item():.4f}, IA: {accuracy.item():.4f}")

    # Save and display generated images at specific epochs
    if (epoch + 1) in [1, 200, 500, 1000, 1200, 1500, 2000 , 4000 , 6000]:
        with torch.no_grad():
            fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
            image_with_label = add_epoch_label_outside(fixed_gen_images, epoch + 1)
            saved_images.append(image_with_label)

# Concatenate all saved images into a 3-column grid
if saved_images:
    concatenated_image = concatenate_images(saved_images, n_cols=3)
    concatenated_image.save(f"{output_dir}/concatenated_images_with_epochs.png")  # Save the concatenated image
    concatenated_image.show()  # Display the concatenated image

"""**COMMENTING OUT KL DIVERGENCE LOSS**"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt

# Assuming Classifier and Generator are defined elsewhere
# and relevant functions are defined (e.g., kl_divergence, cosine_similarity_loss, etc.)

# Model and optimizer setup
csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_normal)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.01, weight_decay=1e-4)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes = 10
batch_size = 128
labels_per_class = 10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 1e-4

# Create output directory if it does not exist
output_dir = 'MNIST-Inversion/new5/'
os.makedirs(output_dir, exist_ok=True)
num_epochs = 2000

# Lists to store metrics
kl_divergence_values = []
cross_entropy_values = []
orthogonality_losses = []
cosine_similarities = []
accuracies = []

# Training loop
for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    # Generate random noise and input PDFs
    noise = torch.randn(batch_size, nz, 1, 1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    # Generate images
    gen_images = gen(noise, input_pdf)

    # Register hooks
    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    # Evaluate with the classifier
    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    # Calculate losses
    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarity = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()
    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    # Total loss calculation
    loss = (
        60 * cosine_similarity
        + 60 * orthogonality_loss
        + 30 * cross_entropy
        #+ 5 * kl_divergence_value
        + lambda_l1 * l1_regularization
    )

    # Backpropagation and optimization step
    loss.backward()
    gen_optimizer.step()

    # Clean up hooks and features
    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    # Store metrics
    kl_divergence_values.append(kl_divergence_value.item())
    cross_entropy_values.append(cross_entropy.item())
    orthogonality_losses.append(orthogonality_loss.item())
    cosine_similarities.append(cosine_similarity.item())
    accuracies.append(accuracy.item())

    # Logging the losses and accuracy
    print(f"Epoch {epoch + 1}/{num_epochs}, KLD: {kl_divergence_value.item():.4f}, "
          f"CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, "
          f"CS: {cosine_similarity.item():.4f}, IA: {accuracy.item():.4f}")

    # Save generated images
    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"{output_dir}/image_{epoch + 1}.png", nrow=10, normalize=True)

# Plotting the metrics after training
plt.figure(figsize=(12, 6))

# Plot accuracy over epochs
plt.plot(accuracies, label='Accuracy (IA)', color='blue')

# Highlight the maximum accuracy
max_accuracy = max(accuracies)
max_epoch = accuracies.index(max_accuracy)
plt.plot(max_epoch, max_accuracy, 'ro')  # mark max point
plt.text(max_epoch, max_accuracy, f'Max IA: {max_accuracy:.4f}', fontsize=10, color='red')

# Add labels and legend
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

"""**COMMENTING OUT L1 REGULARIZATION**"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt

# Assuming Classifier and Generator are defined elsewhere
# and relevant functions are defined (e.g., kl_divergence, cosine_similarity_loss, etc.)

# Model and optimizer setup
csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_normal)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.01, weight_decay=1e-4)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes = 10
batch_size = 128
labels_per_class = 10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 1e-4

# Create output directory if it does not exist
output_dir = 'MNIST-Inversion/new6/'
os.makedirs(output_dir, exist_ok=True)
num_epochs = 2000

# Lists to store metrics
kl_divergence_values = []
cross_entropy_values = []
orthogonality_losses = []
cosine_similarities = []
accuracies = []

# Training loop
for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    # Generate random noise and input PDFs
    noise = torch.randn(batch_size, nz, 1, 1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    # Generate images
    gen_images = gen(noise, input_pdf)

    # Register hooks
    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    # Evaluate with the classifier
    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    # Calculate losses
    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarity = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()
    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    # Total loss calculation
    loss = (
        60 * cosine_similarity
        + 60 * orthogonality_loss
        + 30 * cross_entropy
        + 5 * kl_divergence_value
        #+ lambda_l1 * l1_regularization
    )

    # Backpropagation and optimization step
    loss.backward()
    gen_optimizer.step()

    # Clean up hooks and features
    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    # Store metrics
    kl_divergence_values.append(kl_divergence_value.item())
    cross_entropy_values.append(cross_entropy.item())
    orthogonality_losses.append(orthogonality_loss.item())
    cosine_similarities.append(cosine_similarity.item())
    accuracies.append(accuracy.item())

    # Logging the losses and accuracy
    print(f"Epoch {epoch + 1}/{num_epochs}, KLD: {kl_divergence_value.item():.4f}, "
          f"CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, "
          f"CS: {cosine_similarity.item():.4f}, IA: {accuracy.item():.4f}")

    # Save generated images
    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"{output_dir}/image_{epoch + 1}.png", nrow=10, normalize=True)

# Plotting the metrics after training
plt.figure(figsize=(12, 6))

# Plot accuracy over epochs
plt.plot(accuracies, label='Accuracy (IA)', color='blue')

# Highlight the maximum accuracy
max_accuracy = max(accuracies)
max_epoch = accuracies.index(max_accuracy)
plt.plot(max_epoch, max_accuracy, 'ro')  # mark max point
plt.text(max_epoch, max_accuracy, f'Max IA: {max_accuracy:.4f}', fontsize=10, color='red')

# Add labels and legend
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

"""**KEEPING ONLY CROSS ENTROPY AND ORTHOGONAL LOSS**"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt

# Assuming Classifier and Generator are defined elsewhere
# and relevant functions are defined (e.g., kl_divergence, cosine_similarity_loss, etc.)

# Model and optimizer setup
csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_normal)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.01, weight_decay=1e-4)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes = 10
batch_size = 128
labels_per_class = 10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 1e-4

# Create output directory if it does not exist
output_dir = 'MNIST-Inversion/new7/'
os.makedirs(output_dir, exist_ok=True)
num_epochs = 2000

# Lists to store metrics
kl_divergence_values = []
cross_entropy_values = []
orthogonality_losses = []
cosine_similarities = []
accuracies = []

# Training loop
for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    # Generate random noise and input PDFs
    noise = torch.randn(batch_size, nz, 1, 1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    # Generate images
    gen_images = gen(noise, input_pdf)

    # Register hooks
    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    # Evaluate with the classifier
    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    # Calculate losses
    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarity = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()
    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    # Total loss calculation
    loss = (
        #60 * cosine_similarity
        + 60 * orthogonality_loss
        + 30 * cross_entropy
        #+ 5 * kl_divergence_value
        #+ lambda_l1 * l1_regularization
    )

    # Backpropagation and optimization step
    loss.backward()
    gen_optimizer.step()

    # Clean up hooks and features
    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    # Store metrics
    kl_divergence_values.append(kl_divergence_value.item())
    cross_entropy_values.append(cross_entropy.item())
    orthogonality_losses.append(orthogonality_loss.item())
    cosine_similarities.append(cosine_similarity.item())
    accuracies.append(accuracy.item())

    # Logging the losses and accuracy
    print(f"Epoch {epoch + 1}/{num_epochs}, KLD: {kl_divergence_value.item():.4f}, "
          f"CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, "
          f"CS: {cosine_similarity.item():.4f}, IA: {accuracy.item():.4f}")

    # Save generated images
    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"{output_dir}/image_{epoch + 1}.png", nrow=10, normalize=True)

# Plotting the metrics after training
plt.figure(figsize=(12, 6))

# Plot accuracy over epochs
plt.plot(accuracies, label='Accuracy (IA)', color='blue')

# Highlight the maximum accuracy
max_accuracy = max(accuracies)
max_epoch = accuracies.index(max_accuracy)
plt.plot(max_epoch, max_accuracy, 'ro')  # mark max point
plt.text(max_epoch, max_accuracy, f'Max IA: {max_accuracy:.4f}', fontsize=10, color='red')

# Add labels and legend
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

from google.colab import drive
drive.mount('/content/drive')

!cp -r /content/MNIST-Inversion /content/drive/MyDrive/

"""**KEEPING ONLY CROSS ENTROPY LOSS**"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.utils as vutils
import matplotlib.pyplot as plt

# Assuming Classifier and Generator are defined elsewhere
# and relevant functions are defined (e.g., kl_divergence, cosine_similarity_loss, etc.)

# Model and optimizer setup
csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_normal)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.01, weight_decay=1e-4)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes = 10
batch_size = 128
labels_per_class = 10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 1e-4

# Create output directory if it does not exist
output_dir = 'MNIST-Inversion/new8/'
os.makedirs(output_dir, exist_ok=True)
num_epochs = 2000

# Lists to store metrics
kl_divergence_values = []
cross_entropy_values = []
orthogonality_losses = []
cosine_similarities = []
accuracies = []

# Training loop
for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    # Generate random noise and input PDFs
    noise = torch.randn(batch_size, nz, 1, 1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    # Generate images
    gen_images = gen(noise, input_pdf)

    # Register hooks
    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    # Evaluate with the classifier
    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    # Calculate losses
    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarity = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()
    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    # Total loss calculation
    loss = (
        #60 * cosine_similarity
        #+ 60 * orthogonality_loss
        + 30 * cross_entropy
        #+ 5 * kl_divergence_value
        #+ lambda_l1 * l1_regularization
    )

    # Backpropagation and optimization step
    loss.backward()
    gen_optimizer.step()

    # Clean up hooks and features
    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    # Store metrics
    kl_divergence_values.append(kl_divergence_value.item())
    cross_entropy_values.append(cross_entropy.item())
    orthogonality_losses.append(orthogonality_loss.item())
    cosine_similarities.append(cosine_similarity.item())
    accuracies.append(accuracy.item())

    # Logging the losses and accuracy
    print(f"Epoch {epoch + 1}/{num_epochs}, KLD: {kl_divergence_value.item():.4f}, "
          f"CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, "
          f"CS: {cosine_similarity.item():.4f}, IA: {accuracy.item():.4f}")

    # Save generated images
    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"{output_dir}/image_{epoch + 1}.png", nrow=10, normalize=True)

# Plotting the metrics after training
plt.figure(figsize=(12, 6))

# Plot accuracy over epochs
plt.plot(accuracies, label='Accuracy (IA)', color='blue')

# Highlight the maximum accuracy
max_accuracy = max(accuracies)
max_epoch = accuracies.index(max_accuracy)
plt.plot(max_epoch, max_accuracy, 'ro')  # mark max point
plt.text(max_epoch, max_accuracy, f'Max IA: {max_accuracy:.4f}', fontsize=10, color='red')

# Add labels and legend
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_uniform)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.075, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.01)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  (  6000*cosine_similarilty
              + 10*orthogonality_loss
             + 300*cross_entropy
              + 50*kl_divergence_value
              + lambda_l1*l1_regularization
            )

    loss.backward(retain_graph=True)
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"MNIST-Inversion/new2/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_normal)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.05, weight_decay=5e-4)

mlp = LastLayers(ncf).to(device)
copy_weights(csf, mlp)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 5e-4

num_epochs =1000

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  (  60*cosine_similarilty
             + 5*orthogonality_loss
             + 30*cross_entropy
             + 5*kl_divergence_value
            )

    loss.backward()
    gen_optimizer.step()

    if epoch % 100 == 0:
        selected_features = features0[0].cpu().detach().numpy()
        all_labels = predicted_labels.cpu().detach().numpy()
        save_tsne_plot(selected_features, all_labels, epoch, save_dir='MNIST-Inversion/fin9/tsne')
        save_pca_plot(selected_features, all_labels, epoch, save_dir='MNIST-Inversion/fin9/pca')

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"MNIST-Inversion/fin9/images/image_{epoch + 1}.png", nrow=10, normalize=True)

"""Reconstruction"""

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_normal)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.05, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.01)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

perturbation_bound = 1.95  # Set your overall perturbation bound

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    var_loss=total_variation_loss(gen_images)

    epsilon = torch.rand(1).item() * perturbation_bound
    perturbation = epsilon * torch.sign(torch.randn_like(gen_images))
    perturbed_images = gen_images + perturbation

    #perturbed_images = add_l1_perturbation(gen_images, perturbation_bound)
    #perturbed_images = add_l2_perturbation(gen_images, perturbation_bound)
    #perturbed_images = add_linf_perturbation(gen_images, perturbation_bound)

    csf_outputs = csf(perturbed_images)
    perturbed_pdf = F.softmax(csf_outputs, dim=1)

    perturbation_loss = criterion(csf_outputs, set_labels)

    predicted_labels = torch.argmax(perturbed_pdf, dim=1)
    perturbation_accuracy = (predicted_labels == set_labels).float().mean()

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    perturbed_kl_divergence_value = kl_divergence(perturbed_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  (  7000*cosine_similarilty
              + 10*orthogonality_loss
             + 1000*cross_entropy
              + 500*kl_divergence_value
              + lambda_l1*l1_regularization
               + 1000*perturbation_loss
               + 500*perturbed_kl_divergence_value
               + 50*var_loss
            )


    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, VL:{var_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f},  PKLD:{perturbed_kl_divergence_value.item():.4f},  PE:{perturbation_loss.item():.4f}, CE: {cross_entropy.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}  PA: {perturbation_accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"MNIST-Inversion/new3/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_normal)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.01, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.05)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

perturbation_bound = 1.95  # Set your overall perturbation bound

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    var_loss=total_variation_loss(gen_images)

    epsilon = torch.rand(1).item() * perturbation_bound
    perturbation = epsilon * torch.sign(torch.randn_like(gen_images))
    perturbed_images = gen_images + perturbation

    perturbed_images = add_l1_perturbation(gen_images, perturbation_bound)
    perturbed_images = add_l2_perturbation(gen_images, perturbation_bound)
    perturbed_images = add_linf_perturbation(gen_images, perturbation_bound)

    csf_outputs = csf(perturbed_images)
    perturbed_pdf = F.softmax(csf_outputs, dim=1)

    perturbation_loss = criterion(csf_outputs, set_labels)

    predicted_labels = torch.argmax(perturbed_pdf, dim=1)
    perturbation_accuracy = (predicted_labels == set_labels).float().mean()

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    perturbed_kl_divergence_value = kl_divergence(perturbed_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  (  10000*cosine_similarilty
              + 10*orthogonality_loss
             + 400*cross_entropy
              + 500*kl_divergence_value
              + lambda_l1*l1_regularization
               + 1000*perturbation_loss
               + 1000*perturbed_kl_divergence_value
               + 40*var_loss
            )


    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, VL:{var_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f},  PKLD:{perturbed_kl_divergence_value.item():.4f},  PE:{perturbation_loss.item():.4f}, CE: {cross_entropy.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}  PA: {perturbation_accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"MNIST-Inversion/new4/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_normal)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.05, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.05)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

perturbation_bound = 0.5  # Set your overall perturbation bound

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    var_loss=total_variation_loss(gen_images)

    perturbed_images = add_l2_perturbation(gen_images, perturbation_bound)
    #epsilon = torch.rand(1).item() * perturbation_bound
    #perturbation = epsilon * torch.sign(torch.randn_like(gen_images))
    #perturbed_images = gen_images + perturbation

    csf_outputs = csf(perturbed_images)
    perturbed_pdf = F.softmax(csf_outputs, dim=1)

    perturbation_loss = criterion(csf_outputs, set_labels)

    predicted_labels = torch.argmax(perturbed_pdf, dim=1)
    perturbation_accuracy = (predicted_labels == set_labels).float().mean()

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    perturbed_kl_divergence_value = kl_divergence(perturbed_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  (  10000*cosine_similarilty
              + 1000*cross_entropy
              + 500*kl_divergence_value
              + lambda_l1*l1_regularization
               + 300*perturbation_loss
               + 300*perturbed_kl_divergence_value
               + 100*var_loss
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, VL:{var_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f},  PKLD:{perturbed_kl_divergence_value.item():.4f},  PE:{perturbation_loss.item():.4f}, CE: {cross_entropy.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}  PA: {perturbation_accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"MNIST-Inversion/new5/image_{epoch + 1}.png", nrow=10, normalize=True)

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

gen = Generator(nz, ngf, nc, n_classes).to(device)
#gen.apply(weights_initialization_gen_normal)
#gen.apply(weights_initialization_gen_ortho)
#gen.apply(weights_initialization_gen_xavier)
#gen.apply(weights_initialization_gen_uniform)
gen.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.02, weight_decay=0)

hook0 = csf.main[9].register_forward_hook(hook_function0)
hook1 = csf.main[7].register_forward_hook(hook_function1)

criterion = nn.CrossEntropyLoss(label_smoothing=0.05)

n_classes=10
batch_size=2048
labels_per_class=10

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(100, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

lambda_l1 = 0

num_epochs =2000

perturbation_bound = 3  # Set your overall perturbation bound

for epoch in range(num_epochs):
    gen_optimizer.zero_grad()

    noise = torch.randn(batch_size, nz,1,1).to(device)
    input_pdf = F.softmax(torch.randn(batch_size, n_classes).to(device), dim=1)
    set_labels = torch.argmax(input_pdf, dim=1)

    gen_images = gen(noise, input_pdf)
    var_loss=total_variation_loss(gen_images)

    perturbed_images = add_linf_perturbation(gen_images, perturbation_bound)
    #epsilon = torch.rand(1).item() * perturbation_bound
    #perturbation = epsilon * torch.sign(torch.randn_like(gen_images))
    #perturbed_images = gen_images + perturbation

    csf_outputs = csf(perturbed_images)
    perturbed_pdf = F.softmax(csf_outputs, dim=1)

    perturbation_loss = criterion(csf_outputs, set_labels)

    predicted_labels = torch.argmax(perturbed_pdf, dim=1)
    perturbation_accuracy = (predicted_labels == set_labels).float().mean()

    hook0 = csf.main[9].register_forward_hook(hook_function0)
    hook1 = csf.main[7].register_forward_hook(hook_function1)

    csf.eval()
    csf_outputs = csf(gen_images)
    output_pdf = F.softmax(csf_outputs, dim=1)

    kl_divergence_value = kl_divergence(output_pdf, input_pdf)
    perturbed_kl_divergence_value = kl_divergence(perturbed_pdf, input_pdf)
    cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
    orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])
    cross_entropy = criterion(csf_outputs, set_labels)
    predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
    accuracy = (predicted_labels == set_labels).float().mean()

    l1_regularization = sum(param.abs().sum() for param in gen.parameters())

    loss =  (  10000*cosine_similarilty
              + 1000*cross_entropy
              + 500*kl_divergence_value
              + lambda_l1*l1_regularization
               + 300*perturbation_loss
               + 300*perturbed_kl_divergence_value
               + 200*var_loss
            )

    loss.backward()
    gen_optimizer.step()

    hook0.remove()
    hook1.remove()
    features0.clear()
    features1.clear()

    print(f"Epoch {epoch + 1}/{num_epochs}, VL:{var_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f},  PKLD:{perturbed_kl_divergence_value.item():.4f},  PE:{perturbation_loss.item():.4f}, CE: {cross_entropy.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}  PA: {perturbation_accuracy.item():.4f}")

    with torch.no_grad():
        fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
        vutils.save_image(fixed_gen_images, f"MNIST-Inversion/new6/image_{epoch + 1}.png", nrow=10, normalize=True)

"""Iterative Refinement"""

def inversion(num_steps, gen, gen_optimizer, csf, criterion, device, nz, n_classes, epoch):
    # Create a directory if it doesn't exist
    ood_save_dir = 'Downloads/MNISTX/train/ood'
    os.makedirs(ood_save_dir, exist_ok=True)
    gen.train()
    ibar = tqdm(range(num_steps), desc="Inversion")
    # Wrap the loop with tqdm
    for step in ibar:
        gen_optimizer.zero_grad()
        gen.train()

        noise = torch.randn(5000, nz,1,1).to(device)
        input_pdf = F.softmax(torch.randn(5000, n_classes).to(device), dim=1)
        set_labels = torch.argmax(input_pdf, dim=1)

        # Pass noise and labels through the generator
        gen_images = gen(noise, input_pdf)
        hook0 = csf.main[9].register_forward_hook(hook_function0)
        hook1 = csf.main[7].register_forward_hook(hook_function1)

        csf.eval()
        csf_outputs = csf(gen_images)
        output_pdf = F.softmax(csf_outputs, dim=1)

        kl_divergence_value = kl_divergence(output_pdf, input_pdf)
        cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
        orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

        cross_entropy = criterion(csf_outputs, set_labels)
        predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
        accuracy = (predicted_labels == set_labels).float().mean()

        inversion_loss =  (  100*cosine_similarilty
                + 5*orthogonality_loss
                + 30*cross_entropy
                + 5*kl_divergence_value
                )

        inversion_loss.backward()
        gen_optimizer.step()

        hook0.remove()
        hook1.remove()
        features0.clear()
        features1.clear()

        print(f"\nStep {step + 1}/{num_steps}, IL:{inversion_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

        with torch.no_grad():
            fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
            vutils.save_image(fixed_gen_images, f"MNIST-Generation/fin2/epoch_{epoch}_image_{step + 1}.png", nrow=10, normalize=True)

        ibar.set_postfix({"Inversion Loss": inversion_loss.item()})
        # Save generated images for visualization
        # with torch.no_grad():
    #vutils.save_image(gen_images[0:100].detach(), f"ISS-MNIST/Method_1/11_class_epoch_{epoch}.png", nrow=10, normalize=True)

        # Save individual gen_images in Downloads/mnist_extra/training/ood
    for i, image in enumerate(gen_images[0:5000]):
        filename = os.path.join(ood_save_dir, f"gen_{epoch}_{i + 1}.png")
        vutils.save_image(image, filename, normalize=True)

    # Return the last inversion loss and accuracy
    return inversion_loss.item(), accuracy.item()

class Classifier(nn.Module):
    def __init__(self, nc, ncf):
        super(Classifier, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(nc, ncf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ncf),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ncf, ncf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ncf * 2),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ncf * 2, ncf * 4, 3, 1, 0, bias=False),
            nn.Flatten(),
            nn.Linear(ncf * 100, ncf * 2),
            nn.ReLU(),

            nn.Linear(ncf * 2, 11)
        )

    def forward(self, input):
        return self.main(input)

def calculate_class_weights(dataset):
    # Convert the list of targets to a tensor
    targets_tensor = torch.tensor(dataset.targets)

    # Calculate class weights
    class_counts = torch.bincount(targets_tensor)
    total_samples = len(dataset)

    # Calculate class weights
    class_weights = total_samples / class_counts
    class_weights /= torch.sum(class_weights)

    return class_weights

n_classes=11
labels_per_class=10
fixed_batch_size=110

criterion = nn.CrossEntropyLoss()

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(fixed_batch_size, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

csf = Classifier(nc, ncf).to(device)
gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_normal)

gen.train(), csf.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.01, weight_decay=0)
csf_optimizer = optim.Adam(csf.parameters(), lr=0.0001, weight_decay=0)

# Lists to store the training and testing loss and accuracy values
train_losses = []
train_accuracies = []
test_losses = []
test_accuracies = []
inversion_losses = []
inversion_accuracies = []

# Initialize variables to track the best test accuracy and associated epoch
best_test_accuracy = 0.0
best_epoch = 0
class_weights = calculate_class_weights(train_dataset).to(device)
csf_criterion = nn.CrossEntropyLoss(weight=class_weights)

# Training loop for 10 epochs
num_steps =500
num_epochs = 25
for epoch in range(0,num_epochs):
    # Training
    train_loss, train_accuracy = train(csf, train_loader, csf_optimizer, csf_criterion, device)
    train_losses.append(train_loss)
    train_accuracies.append(train_accuracy)

    # Testing
    test_loss, test_accuracy = test(csf, test_loader, device)
    test_losses.append(test_loss)
    test_accuracies.append(test_accuracy)

    #gen = Generator(nz, ngf, nc, n_classes).to(device)
    #gen.train()
    #gen_optimizer = optim.Adam(gen.parameters(), lr=0.001)

    # Inversion
    inversion_loss, inversion_accuracy = inversion(num_steps, gen, gen_optimizer, csf, criterion, device, nz, n_classes, epoch + 1)
    inversion_losses.append(inversion_loss)
    inversion_accuracies.append(inversion_accuracy)

    # Redefine the dataset, dataloader, class weights, csf_criterion
    train_dataset = ImageFolder(root=train_data_dir, transform=train_transform)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)
    class_weights = calculate_class_weights(train_dataset).to(device)

    # Define CrossEntropyLoss with weights
    csf_criterion = nn.CrossEntropyLoss(weight=class_weights)

    print(f"\nEpoch {epoch + 1}/{num_epochs}")
    print(f"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}")
    print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")
    print(f"Inversion Loss: {inversion_loss:.4f}, Inversion Accuracy: {inversion_accuracy:.4f}\n")


    # Check if the current test_accuracy is the best so far
    if test_accuracy > best_test_accuracy:
        best_test_accuracy = test_accuracy
        best_epoch = epoch + 1  # Store the epoch number of the best accuracy
        # Save the model
        torch.save(csf.state_dict(), f'best_csf_model_epoch_{best_epoch}.pth')
        print(f"New best test accuracy: {best_test_accuracy:.4f} at epoch {best_epoch}. Model saved.")

# Print the overall best accuracy and epoch after training is complete
print(f"Best Test Accuracy: {best_test_accuracy:.4f} at Epoch {best_epoch}")

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

# Define transforms for preprocessing
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# Download and load CIFAR-10 dataset
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)

# Define the CNN model
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(128 * 4 * 4, 512)
        self.fc2 = nn.Linear(512, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        x = x.view(-1, 128 * 4 * 4)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Initialize the network, loss function, and optimizer
net = Net()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters(), lr=0.001)

# Training the model
for epoch in range(10):  # Loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        optimizer.zero_grad()

        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        if i % 100 == 99:    # Print every 100 mini-batches
            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')
            running_loss = 0.0

print('Finished Training')

# Testing the model
correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')

# Save the trained model
torch.save(net.state_dict(), 'cifar10_cnn.pth')

