# -*- coding: utf-8 -*-
"""OOD_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mm09OGgmjuFb37m0ZS7DwtdWuNJV0V4m
"""

import os
import cv2
import glob
import torch
import numpy as np
from PIL import Image
import torch.nn as nn
from tqdm import tqdm
import torch.optim as optim
import torchvision.utils as vutils
import torch.nn.functional as F
import matplotlib.pyplot as plt
from torchvision import transforms
from torch.utils.data import Dataset
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms.functional as TF
from sklearn.preprocessing import MinMaxScaler
from torchvision.datasets import ImageFolder
from torchvision import datasets, transforms

import os
import shutil
from torchvision import datasets

# Define paths
mnist_root = './data/MNIST'
train_data_dir = os.path.join(mnist_root, 'train')
test_data_dir = os.path.join(mnist_root, 'test')

# Make sure the directories exist
os.makedirs(train_data_dir, exist_ok=True)
os.makedirs(test_data_dir, exist_ok=True)

# Download the MNIST dataset
train_set = datasets.MNIST(root=mnist_root, train=True, download=True)
test_set = datasets.MNIST(root=mnist_root, train=False, download=True)

# Move images into class-specific folders
for idx, (image, label) in enumerate(train_set):
    label_dir = os.path.join(train_data_dir, str(label))
    os.makedirs(label_dir, exist_ok=True)
    image.save(os.path.join(label_dir, f"{idx}.png"))

for idx, (image, label) in enumerate(test_set):
    label_dir = os.path.join(test_data_dir, str(label))
    os.makedirs(label_dir, exist_ok=True)
    image.save(os.path.join(label_dir, f"{idx}.png"))

# Define the path to your MNIST dataset
train_data_dir = 'data/MNIST/train'
test_data_dir = 'data/MNIST/test'

# Set device (CPU or GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define data transformations with MNIST mean and standard deviation
mnist_mean = 0.1307
mnist_std = 0.3081
batch_size= 1024
# Define data transformations for training and testing
train_transform = transforms.Compose([
    transforms.RandomRotation(degrees=(-20, 20)),
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.9, 1.1)),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
    transforms.RandomGrayscale(p=0.1),
    transforms.RandomAffine(degrees=(-10, 10), translate=(0.1, 0.1), scale=(0.9, 1.1), shear=(-10, 10)),
    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize(28),
    transforms.ToTensor(),
    transforms.Normalize((mnist_mean,), (mnist_std,))
])

test_transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize(28),
    transforms.ToTensor(),
    transforms.Normalize((mnist_mean,), (mnist_std,))
])

# Load the MNIST dataset using ImageFolder
# train_dataset = ImageFolder(root=train_data_dir, transform=train_transform)
# test_dataset = ImageFolder(root=test_data_dir, transform=test_transform)
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=train_transform)
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=test_transform)


# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory = True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory = True)

print("Training Dataset:")
print(f"  Size: {len(train_dataset)}")
print(f"  Shape: {next(iter(train_loader))[0].shape}")
print(f"  Batch Size: {train_loader.batch_size}")

print("\nTesting Dataset:")
print(f"  Size: {len(test_dataset)}")
print(f"  Shape: {next(iter(test_loader))[0].shape}")
print(f"  Batch Size: {test_loader.batch_size}")

# Dictionary to store images for each class
class_images = {i: [] for i in range(10)}

# Traverse through the folder and collect images
for class_label in range(10):
    class_path = os.path.join(train_data_dir, str(class_label))

    # Iterate through images in the class folder
    for image_file in os.listdir(class_path)[:10]:
        image_path = os.path.join(class_path, image_file)
        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        class_images[class_label].append(image)

# Plot 10x10 grid
fig, axs = plt.subplots(10, 10, figsize=(10, 10))

for i in range(10):
    for j in range(10):
        axs[i, j].imshow(class_images[i][j], cmap="gray")
        axs[i, j].axis("off")

plt.show()

"""Classifier"""

class Classifier(nn.Module):
    def __init__(self, nc, ncf):
        super(Classifier, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(nc, ncf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ncf),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ncf, ncf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ncf * 2),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ncf * 2, ncf * 4, 3, 1, 0, bias=False),
            nn.Flatten(),
            nn.Linear(ncf * 100, ncf * 2),
            nn.ReLU(),

            nn.Linear(ncf * 2, 10)
        )

    def forward(self, input):
        return self.main(input)

"""We have defined a CNN here, the output is a 10 element 1D vector with probabilities of possible values the image has between 0 and 9."""

class Generator(nn.Module):
    def __init__(self, nz, ngf, nc, n_classes):
        super(Generator, self).__init__()
        # Linear layer to map the softmaxed vector to the size nz
        self.embed = nn.Linear(n_classes, nz)

        # The main model architecture remains unchanged
        self.main = nn.Sequential(
            nn.ConvTranspose2d(nz * 2, ngf * 4, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.Dropout2d(0.2),
            nn.Dropout2d(0.3),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.Dropout2d(0.2),
            nn.Dropout2d(0.3),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 2, bias=False),
            nn.BatchNorm2d(ngf),
            nn.Dropout2d(0.2),
            nn.Dropout2d(0.3),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, z, class_vector):
        # Map the class vector to the latent space size
        embed_vector = self.embed(class_vector).unsqueeze(-1).unsqueeze(-1)
        # Concatenate with the latent vector z
        input = torch.cat([z, embed_vector], 1)
        return self.main(input)

"""The Generator class in this code creates synthetic images by combining a noise vector and a class label vector, using transposed convolutions to upsample the input into a high-resolution image. It also employs batch normalization and dropout to enhance learning and prevent overfitting."""

def weights_initialization_cnn(m):
    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)

"""The weights_initialization_cnn function initializes the weights of convolutional and linear layers using He initialization to promote effective training, especially for ReLU activation functions. It also sets biases to zero if they exist, ensuring a balanced starting point for training."""

def train(model, train_loader, optimizer, criterion, device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc="Training")

    for i, (inputs, labels) in pbar:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        pbar.set_postfix({"Batch Loss": loss.item()})

    average_loss = running_loss / len(train_loader)
    accuracy = correct / total

    return average_loss, accuracy

"""The train function trains a neural network for one epoch, calculating the average loss and accuracy. It handles data transfer to the appropriate device, performs forward and backward passes, updates model parameters, and uses a progress bar to monitor training progress."""

def test(model, test_loader, device):
    model.eval()
    correct = 0
    total = 0
    running_loss = 0.0

    with torch.no_grad():
        pbar = tqdm(enumerate(test_loader), total=len(test_loader), desc="Testing")

        for i, (inputs, labels) in pbar:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            running_loss += loss.item()

            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            pbar.set_postfix({"Batch Loss": loss.item()})

    average_loss = running_loss / len(test_loader)
    accuracy = correct / total

    return average_loss, accuracy

"""The test function evaluates a neural network on the test dataset without updating the model parameters. It calculates the average loss and accuracy, using torch.no_grad() to optimize performance and ensure consistent evaluation behavior.

___________------------------------------------------_______________
"""

# Classifier Hyperparameters
ncf = 64  # Number of classifier filters
nc = 1    # Number of channels in the input images (1 for grayscale)

# Initialize your model, optimizer, and criterion
csf = Classifier(nc, ncf).to(device)
csf.apply(weights_initialization_cnn)

csf_optimizer = optim.Adam(csf.parameters(), lr=0.0001)
criterion = nn.CrossEntropyLoss()

# Lists to store the training and testing loss and accuracy values
train_losses = []
train_accuracies = []
test_losses = []
test_accuracies = []

# Variable to store the best test accuracy
best_test_accuracy = 0.0
best_model_state = None

# Add the following code after the training loop, before saving the model
import os

# Define the directory where you want to save the model
save_dir = 'MNIST-Inversion'

# Create the directory if it doesn't exist
os.makedirs(save_dir, exist_ok=True)

# Save the best model
if best_model_state is not None:
    model_save_path = os.path.join(save_dir, 'mnist_csf_10.pth')
    torch.save(best_model_state, model_save_path)
    print(f"Best model saved with test accuracy: {best_test_accuracy:.4f}")
else:
    print("No model was saved.")

"""The script trains a classifier model for a specified number of epochs, evaluates it on test data, and tracks performance metrics. It identifies and saves the model with the highest test accuracy."""

csf = Classifier(nc, ncf).to(device)
csf.load_state_dict(torch.load('MNIST-Inversion/mnist_csf_10.pth'))

"""**FROM BELOW**"""

features0=[]
def hook_function0(module, input, output):
    # This function saves the output of the layer to the global list 'features0'
    features0.append(output.clone())
features1=[]
def hook_function1(module, input, output):
    # This function saves the output of the layer to the global list 'features1'
    features1.append(output.clone())

def generate_ordered_labels(n_classes, labels_per_class):
    # Create a tensor of labels from 0 to n_classes - 1, each repeated repeats_per_class times
    labels = torch.arange(n_classes).repeat_interleave(labels_per_class)
    return labels

def generate_sorted_input_pdf(batch_size, n_classes, nz, samples_per_class=10, device=None):
    # Generate noise
    noise = torch.randn(batch_size, nz,1,1, device=device)

    # Ensure enough samples to select exactly 'samples_per_class' per class
    initial_batch_size = 250
    input_pdf_large = F.softmax(torch.rand(initial_batch_size, n_classes, device=device), dim=1)

    # Sort input_pdf based on argmax values to evenly distribute and order classes
    set_labels_large = torch.argmax(input_pdf_large, dim=1)
    sorted_indices = torch.argsort(set_labels_large)
    ordered_input_pdf = input_pdf_large[sorted_indices]

    # Ensure we pick exactly 'samples_per_class' for each class
    input_pdf = torch.zeros((batch_size, n_classes), device=device)
    for i in range(n_classes):
        indices = (set_labels_large == i).nonzero(as_tuple=True)[0][:samples_per_class]
        input_pdf[i * samples_per_class:(i + 1) * samples_per_class] = input_pdf_large[indices]

    return noise, input_pdf

# Example usage:
batch_size = 100  # 10 classes * 10 samples each
n_classes = 10
nz = 100  # Example size for the noise dimension
noise, input_pdf = generate_sorted_input_pdf(batch_size, n_classes, nz)

print("Noise Shape:", noise.shape)
print("Input PDF Shape:", input_pdf)
print("Input PDF Shape:", input_pdf.shape)
print("Set Labels (Sorted):", torch.argmax(input_pdf, dim=1))

def generate_ordered_one_hot_noise(batch_size, n_classes, nz, samples_per_class=10, device=None):
    # Generate noise
    noise = torch.randn(batch_size, nz, 1, 1, device=device)

    # Generate one-hot labels in order from 0 to n_classes-1
    labels = torch.arange(n_classes).repeat_interleave(samples_per_class).to(device)
    one_hot_labels = torch.nn.functional.one_hot(labels, num_classes=n_classes).float()

    return noise, one_hot_labels

def weights_initialization_gen_xavier(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.xavier_normal_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

def weights_initialization_gen_ortho(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.orthogonal_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

def weights_initialization_gen_normal(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.normal_(m.weight, mean=0.0, std=0.02)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

def weights_initialization_gen_uniform(m):
    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):
        nn.init.uniform_(m.weight, -0.08, 0.08)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

def cosine_similarity_loss(features):
    normalized_features = F.normalize(features, p=2, dim=1)
    similarity_matrix = torch.mm(normalized_features, normalized_features.t())
    mask = torch.eye(similarity_matrix.size(0), device=similarity_matrix.device).bool()
    similarity_matrix = similarity_matrix.masked_fill(mask, 0)
    loss = similarity_matrix.sum() / (features.size(0) * (features.size(0) - 1))
    return loss  # Minimize

def feature_orthogonality_loss(features):
    gram_matrix = torch.mm(features, features.t())
    identity_matrix = torch.eye(gram_matrix.size(0), device=gram_matrix.device)
    loss = torch.mean((gram_matrix - identity_matrix) ** 2)
    return loss / (features.size(0) * features.size(1))  # Minimize

def kl_divergence(p, q):

    p = F.softmax(p, dim=1)
    q = F.softmax(q, dim=1)

    kl_div = F.kl_div(p.log(), q, reduction='batchmean')

    return kl_div

def add_l1_perturbation(images, perturbation_bound):
    # Generate random perturbation
    perturbation = torch.randn_like(images)

    # Normalize the perturbation to have an L1 norm of 1
    perturbation = perturbation / perturbation.abs().sum(dim=[1, 2, 3], keepdim=True)

    # Scale perturbation by the L1 bound
    perturbation = perturbation * perturbation_bound

    # Add the perturbation to the images
    perturbed_images = images + perturbation

    return perturbed_images

def add_l2_perturbation(images, perturbation_bound):
    # Generate random perturbation
    perturbation = torch.randn_like(images)

    # Normalize the perturbation to have an L2 norm of 1
    perturbation = perturbation / perturbation.view(perturbation.size(0), -1).norm(p=2, dim=1).view(-1, 1, 1, 1)

    # Scale perturbation by the L2 bound
    perturbation = perturbation * perturbation_bound

    # Add the perturbation to the images
    perturbed_images = images + perturbation

    return perturbed_images

def add_linf_perturbation(images, perturbation_bound):
    # Generate random perturbation
    perturbation = torch.randn_like(images)

    # Scale the perturbation so that its maximum absolute value does not exceed the perturbation bound
    perturbation = perturbation_bound * torch.sign(perturbation)

    # Add the perturbation to the images
    perturbed_images = images + perturbation

    return perturbed_images

def total_variation_loss(generated_images):
    """
    Computes the Total Variation Loss for a batch of generated images.

    Parameters:
    generated_images (torch.Tensor): A batch of generated images of shape (batch_size, channels, height, width).

    Returns:
    torch.Tensor: The total variation loss.
    """
    batch_size = generated_images.size(0)
    h_variation = torch.pow(generated_images[:, :, 1:, :] - generated_images[:, :, :-1, :], 2).sum()
    w_variation = torch.pow(generated_images[:, :, :, 1:] - generated_images[:, :, :, :-1], 2).sum()

    return (h_variation + w_variation) / batch_size

"""Iterative Refinement"""

def inversion(num_steps, gen, gen_optimizer, csf, criterion, device, nz, n_classes, epoch):
    # Create a directory if it doesn't exist
    ood_save_dir = 'Downloads/MNISTX/train/ood'
    os.makedirs(ood_save_dir, exist_ok=True)
    gen.train()
    ibar = tqdm(range(num_steps), desc="Inversion")
    # Wrap the loop with tqdm
    for step in ibar:
        gen_optimizer.zero_grad()
        gen.train()

        noise = torch.randn(5000, nz,1,1).to(device)
        input_pdf = F.softmax(torch.randn(5000, n_classes).to(device), dim=1)
        set_labels = torch.argmax(input_pdf, dim=1)

        # Pass noise and labels through the generator
        gen_images = gen(noise, input_pdf)
        hook0 = csf.main[9].register_forward_hook(hook_function0)
        hook1 = csf.main[7].register_forward_hook(hook_function1)

        csf.eval()
        csf_outputs = csf(gen_images)
        output_pdf = F.softmax(csf_outputs, dim=1)

        kl_divergence_value = kl_divergence(output_pdf, input_pdf)
        cosine_similarilty = cosine_similarity_loss(features0[0]) + cosine_similarity_loss(features1[0])
        orthogonality_loss = feature_orthogonality_loss(features0[0]) + feature_orthogonality_loss(features1[0])

        cross_entropy = criterion(csf_outputs, set_labels)
        predicted_labels = torch.argmax(F.log_softmax(csf_outputs, dim=1), dim=1)
        accuracy = (predicted_labels == set_labels).float().mean()

        inversion_loss =  (  100*cosine_similarilty
                + 5*orthogonality_loss
                + 30*cross_entropy
                + 5*kl_divergence_value
                )

        inversion_loss.backward()
        gen_optimizer.step()

        hook0.remove()
        hook1.remove()
        features0.clear()
        features1.clear()

        print(f"\nStep {step + 1}/{num_steps}, IL:{inversion_loss.item():.4f}, KLD:{kl_divergence_value.item():.4f}, CE: {cross_entropy.item():.4f}, OL: {orthogonality_loss.item():.4f}, CS: {cosine_similarilty.item():.4f}, IA: {accuracy.item():.4f}")

        with torch.no_grad():
            fixed_gen_images = gen(fixed_noise, fixed_input_pdf)
            vutils.save_image(fixed_gen_images, f"MNIST-Generation/fin2/epoch_{epoch}_image_{step + 1}.png", nrow=10, normalize=True)

        ibar.set_postfix({"Inversion Loss": inversion_loss.item()})
        # Save generated images for visualization
        # with torch.no_grad():
    #vutils.save_image(gen_images[0:100].detach(), f"ISS-MNIST/Method_1/11_class_epoch_{epoch}.png", nrow=10, normalize=True)

        # Save individual gen_images in Downloads/mnist_extra/training/ood
    for i, image in enumerate(gen_images[0:5000]):
        filename = os.path.join(ood_save_dir, f"gen_{epoch}_{i + 1}.png")
        vutils.save_image(image, filename, normalize=True)

    # Return the last inversion loss and accuracy
    return inversion_loss.item(), accuracy.item()

class Classifier(nn.Module):
    def __init__(self, nc, ncf):
        super(Classifier, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(nc, ncf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ncf),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ncf, ncf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ncf * 2),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ncf * 2, ncf * 4, 3, 1, 0, bias=False),
            nn.Flatten(),
            nn.Linear(ncf * 100, ncf * 2),
            nn.ReLU(),

            nn.Linear(ncf * 2, 10)
        )

    def forward(self, input):
        return self.main(input)

def calculate_class_weights(dataset):
    # Convert the list of targets to a tensor
    targets_tensor = torch.tensor(dataset.targets)

    # Calculate class weights
    class_counts = torch.bincount(targets_tensor)
    total_samples = len(dataset)

    # Calculate class weights
    class_weights = total_samples / class_counts
    class_weights /= torch.sum(class_weights)

    return class_weights

n_classes=10
labels_per_class=10
fixed_batch_size=100
ngf=16
criterion = nn.CrossEntropyLoss()

fixed_noise, fixed_input_pdf = generate_sorted_input_pdf(fixed_batch_size, n_classes, nz)
fixed_noise = fixed_noise.to(device)
fixed_input_pdf = fixed_input_pdf.to(device)

csf = Classifier(nc, ncf).to(device)
gen = Generator(nz, ngf, nc, n_classes).to(device)
gen.apply(weights_initialization_gen_normal)

gen.train(), csf.train()
gen_optimizer = optim.Adam(gen.parameters(), lr=0.01, weight_decay=0)
csf_optimizer = optim.Adam(csf.parameters(), lr=0.0001, weight_decay=0)

# Lists to store the training and testing loss and accuracy values
train_losses = []
train_accuracies = []
test_losses = []
test_accuracies = []
inversion_losses = []
inversion_accuracies = []

# Initialize variables to track the best test accuracy and associated epoch
best_test_accuracy = 0.0
best_epoch = 0
class_weights = calculate_class_weights(train_dataset).to(device)
csf_criterion = nn.CrossEntropyLoss(weight=class_weights)

# Training loop for 10 epochs
num_steps =500
num_epochs = 25
for epoch in range(0,num_epochs):
    # Training
    train_loss, train_accuracy = train(csf, train_loader, csf_optimizer, csf_criterion, device)
    train_losses.append(train_loss)
    train_accuracies.append(train_accuracy)

    # Testing
    test_loss, test_accuracy = test(csf, test_loader, device)
    test_losses.append(test_loss)
    test_accuracies.append(test_accuracy)

    #gen = Generator(nz, ngf, nc, n_classes).to(device)
    #gen.train()
    #gen_optimizer = optim.Adam(gen.parameters(), lr=0.001)

    # Inversion
    inversion_loss, inversion_accuracy = inversion(num_steps, gen, gen_optimizer, csf, criterion, device, nz, n_classes, epoch + 1)
    inversion_losses.append(inversion_loss)
    inversion_accuracies.append(inversion_accuracy)

    # Redefine the dataset, dataloader, class weights, csf_criterion
    train_dataset = ImageFolder(root=train_data_dir, transform=train_transform)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)
    class_weights = calculate_class_weights(train_dataset).to(device)

    # Define CrossEntropyLoss with weights
    csf_criterion = nn.CrossEntropyLoss(weight=class_weights)

    print(f"\nEpoch {epoch + 1}/{num_epochs}")
    print(f"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}")
    print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")
    print(f"Inversion Loss: {inversion_loss:.4f}, Inversion Accuracy: {inversion_accuracy:.4f}\n")


    # Check if the current test_accuracy is the best so far
    if test_accuracy > best_test_accuracy:
        best_test_accuracy = test_accuracy
        best_epoch = epoch + 1  # Store the epoch number of the best accuracy
        # Save the model
        torch.save(csf.state_dict(), f'best_csf_model_epoch_{best_epoch}.pth')
        print(f"New best test accuracy: {best_test_accuracy:.4f} at epoch {best_epoch}. Model saved.")

# Print the overall best accuracy and epoch after training is complete
print(f"Best Test Accuracy: {best_test_accuracy:.4f} at Epoch {best_epoch}")

